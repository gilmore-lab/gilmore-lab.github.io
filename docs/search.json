[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "resources",
    "section": "",
    "text": "New Lab Member Instructions\nWe use Paperpile for reference management. Please use the Paperpile Instructions to utilize this web based reference management system.\n\n\n\nR for Data Science"
  },
  {
    "objectID": "resources.html#lab-resources",
    "href": "resources.html#lab-resources",
    "title": "resources",
    "section": "",
    "text": "New Lab Member Instructions\nWe use Paperpile for reference management. Please use the Paperpile Instructions to utilize this web based reference management system.\n\n\n\nR for Data Science"
  },
  {
    "objectID": "resources.html#active-projects",
    "href": "resources.html#active-projects",
    "title": "resources",
    "section": "Active Projects",
    "text": "Active Projects\n\nMotion Coherence (MOCO)\n\nInfant High Density EEG Data\n\nGitHub\n\nDatabrary\n\n\nChild Behavioral Data\n\nGitHub\n\nDatabrary\n\n\nAdult Behavioral Data\n\nGitHub\n\nDatabrary\n\n\n\n\nMotion Form (MOFO)\n\nChild High Density EEG Data\n\nGitHub\n\nDatabrary\n\n\n\n\nSize Matters\n\nData\n\nGitHub\n\n\n\n\nSymmetry\n\nAdult Behavorial Data\n\nGitHub\n\nDatabrary"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html",
    "href": "talk-slides/munafo-etal-2017.html",
    "title": "munafo-etal-2017",
    "section": "",
    "text": "Munafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Sert, N. P. du, … Ioannidis, J. P. A. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. https://doi.org/10.1038/s41562-016-0021."
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#discussion-of",
    "href": "talk-slides/munafo-etal-2017.html#discussion-of",
    "title": "munafo-etal-2017",
    "section": "",
    "text": "Munafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Sert, N. P. du, … Ioannidis, J. P. A. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. https://doi.org/10.1038/s41562-016-0021."
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#steps-in-scientific-method",
    "href": "talk-slides/munafo-etal-2017.html#steps-in-scientific-method",
    "title": "munafo-etal-2017",
    "section": "Steps in scientific method",
    "text": "Steps in scientific method\n\nGenerate and specify hypothesis\nDesign study\nConduct study and collect data\nAnalyze data and test hypothesis\nInterpret results\nPublish and/or conduct next study"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#failure-to-control-for-bias",
    "href": "talk-slides/munafo-etal-2017.html#failure-to-control-for-bias",
    "title": "munafo-etal-2017",
    "section": "Failure to control for bias",
    "text": "Failure to control for bias\n\nApophenia\nConfirmation bias\nHindsight bias"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#low-statistical-power",
    "href": "talk-slides/munafo-etal-2017.html#low-statistical-power",
    "title": "munafo-etal-2017",
    "section": "Low statistical power",
    "text": "Low statistical power\n\nStatistical Power: probability that study will detect an effect, when one actually exists.\n\nHow big is effect?\nHow big and how variable is sample?"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#is-psychological-science-underpowered",
    "href": "talk-slides/munafo-etal-2017.html#is-psychological-science-underpowered",
    "title": "munafo-etal-2017",
    "section": "Is psychological science underpowered?",
    "text": "Is psychological science underpowered?\n\nButton, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376. https://doi.org/10.1038/nrn3475\nIoannidis, J. P. A. (2005). Why Most Published Research Findings Are False. PLOS Medicine, 2(8), e124. https://doi.org/10.1371/journal.pmed.0020124"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#is-psychological-science-underpowered-1",
    "href": "talk-slides/munafo-etal-2017.html#is-psychological-science-underpowered-1",
    "title": "munafo-etal-2017",
    "section": "Is psychological science underpowered?",
    "text": "Is psychological science underpowered?\n\nSzucs, D., & Ioannidis, J. P. (2016). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. bioRxiv, 071530. https://doi.org/10.1101/071530\n“We have empirically assessed the distribution of published effect sizes and estimated power by extracting more than 100,000 statistical records from about 10,000 cognitive neuroscience and psychology papers published during the past 5 years.”"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#szucs-ioannides-2016",
    "href": "talk-slides/munafo-etal-2017.html#szucs-ioannides-2016",
    "title": "munafo-etal-2017",
    "section": "Szucs & Ioannides 2016",
    "text": "Szucs & Ioannides 2016\n\n“Median power to detect small, medium and large effects was 0.12, 0.44 and 0.73.”\n“False report probability is likely to exceed 50% for the whole literature.”"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#poor-quality-control",
    "href": "talk-slides/munafo-etal-2017.html#poor-quality-control",
    "title": "munafo-etal-2017",
    "section": "Poor quality control",
    "text": "Poor quality control\n\nGoodman, S. N., Fanelli, D., & Ioannidis, J. P. A. (2016). What does research reproducibility mean? Science Translational Medicine, 8(341), 341ps12–341ps12. https://doi.org/10.1126/scitranslmed.aaf5027\nMethods reproducibility\n\n“…the ability to implement, as exactly as possible, the experimental and computational procedures, with the same data and tools, to obtain the same results.”"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#p-hacking",
    "href": "talk-slides/munafo-etal-2017.html#p-hacking",
    "title": "munafo-etal-2017",
    "section": "P-Hacking",
    "text": "P-Hacking\n\nSimonsohn, U., Nelson, L. D., & Simmons, J. P. (2014). P-curve: A key to the file-drawer. Journal of Experimental Psychology: General, 143(2), 534–547. https://doi.org/10.1037/a0033242\nhttp://www.p-curve.com/\np-curve app\nIf an effect is true, the distribution of reported p values should be right-skewed (long right tail)"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#harking-hypothesizing-after-the-results-are-known",
    "href": "talk-slides/munafo-etal-2017.html#harking-hypothesizing-after-the-results-are-known",
    "title": "munafo-etal-2017",
    "section": "HARKing: hypothesizing after the results are known",
    "text": "HARKing: hypothesizing after the results are known\n\nKerr, N. L. (1998). HARKing: Hypothesizing After the Results are Known. Personality and Social Psychology Review, 2(3), 196–217. https://doi.org/10.1207/s15327957pspr0203_4\nFind an effect in data analysis\nPresent effect as if it had been hypothesized"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#publication-bias",
    "href": "talk-slides/munafo-etal-2017.html#publication-bias",
    "title": "munafo-etal-2017",
    "section": "Publication bias",
    "text": "Publication bias\n\nResults vs. null findings\nNovel results vs. replications\nCounter-intuitive findings\nFile drawer effect\n\nHow many unpublished failures to replicate sit in file drawers?"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#performing-research",
    "href": "talk-slides/munafo-etal-2017.html#performing-research",
    "title": "munafo-etal-2017",
    "section": "Performing research",
    "text": "Performing research\n\nProtecting against cognitive biases\nImproving methodological training\nImplementing independent methological support\nEncouraging collaboration and team science"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#reporting-on-research",
    "href": "talk-slides/munafo-etal-2017.html#reporting-on-research",
    "title": "munafo-etal-2017",
    "section": "Reporting on research",
    "text": "Reporting on research\n\nPromoting study pre-registration\n\nRegistered reports (Munafo et al. 2017, Box 3)\n\nImproving the quality of reporting\n\nThe Transparency and Openness Promotion (TOP) guidelines and signatories"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#reporting-on-research-1",
    "href": "talk-slides/munafo-etal-2017.html#reporting-on-research-1",
    "title": "munafo-etal-2017",
    "section": "Reporting on research",
    "text": "Reporting on research\n\nFranco, A., Malhotra, N., & Simonovits, G. (2016). Underreporting in Psychology Experiments: Evidence From a Study Registry. Social Psychological and Personality Science, 7(1), 8–12. https://doi.org/10.1177/1948550615598377\n“We find that about 40% of studies fail to fully report all experimental conditions and about 70% of studies do not report all outcome variables included in the questionnaire. Reported effect sizes are about twice as large as unreported effect sizes and are about 3 times more likely to be statistically significant.”"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#verifying-research",
    "href": "talk-slides/munafo-etal-2017.html#verifying-research",
    "title": "munafo-etal-2017",
    "section": "Verifying research",
    "text": "Verifying research\n\nPromoting transparency and open science"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#evaluating-research",
    "href": "talk-slides/munafo-etal-2017.html#evaluating-research",
    "title": "munafo-etal-2017",
    "section": "Evaluating research",
    "text": "Evaluating research\n\nDiversifying peer review"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#changing-incentives",
    "href": "talk-slides/munafo-etal-2017.html#changing-incentives",
    "title": "munafo-etal-2017",
    "section": "Changing Incentives",
    "text": "Changing Incentives\nHigginson, A. D., & Munafò, M. R. (2016). Current Incentives for Scientists Lead to Underpowered Studies with Erroneous Conclusions. PLOS Biology, 14(11), e2000995. https://doi.org/10.1371/journal.pbio.2000995\n\nBadge system"
  },
  {
    "objectID": "talk-slides/munafo-etal-2017.html#status-reportrecommendations-by-stakeholder-group",
    "href": "talk-slides/munafo-etal-2017.html#status-reportrecommendations-by-stakeholder-group",
    "title": "munafo-etal-2017",
    "section": "Status report/recommendations by stakeholder group",
    "text": "Status report/recommendations by stakeholder group\n\n\n\nSource: http://www.nature.com/articles/s41562-016-0021/tables/1"
  },
  {
    "objectID": "talk-slides/how-to-read-academic-paper.html",
    "href": "talk-slides/how-to-read-academic-paper.html",
    "title": "How to Read and Academic Paper",
    "section": "",
    "text": "Read carefully of just skim\n\nThe goal of this research\n\nWhy is it interesting for us to think/talk about?\n\n\n\n\n\nResearch Question?\nHypotheses?\nFindingis?\n\n\n\n\n\nPopulation (age, gender, …), time, locations, etc.\nWhat are DVs and IVs?\nHow are thy measuresed? Why to use it rather than the other?"
  },
  {
    "objectID": "talk-slides/how-to-read-academic-paper.html#why-does-this-paper-matter",
    "href": "talk-slides/how-to-read-academic-paper.html#why-does-this-paper-matter",
    "title": "How to Read and Academic Paper",
    "section": "",
    "text": "Read carefully of just skim\n\nThe goal of this research\n\nWhy is it interesting for us to think/talk about?"
  },
  {
    "objectID": "talk-slides/how-to-read-academic-paper.html#what-does-it-talk-about",
    "href": "talk-slides/how-to-read-academic-paper.html#what-does-it-talk-about",
    "title": "How to Read and Academic Paper",
    "section": "",
    "text": "Research Question?\nHypotheses?\nFindingis?"
  },
  {
    "objectID": "talk-slides/how-to-read-academic-paper.html#what-are-the-methods-it-used",
    "href": "talk-slides/how-to-read-academic-paper.html#what-are-the-methods-it-used",
    "title": "How to Read and Academic Paper",
    "section": "",
    "text": "Population (age, gender, …), time, locations, etc.\nWhat are DVs and IVs?\nHow are thy measuresed? Why to use it rather than the other?"
  },
  {
    "objectID": "who-we-are.html",
    "href": "who-we-are.html",
    "title": "People",
    "section": "",
    "text": "The Brain and Behavioral Dynamics Lab, part of the Psychology Department at Penn State, is looking for research assistants to study brain development in infants, children, and adolescents for Fall 2023. You can earn research project (PSY 494) credit or work study funds, and learn video, computer, and communication skills. Prior research experience and computer skills are a plus, but aren’t required. We are especially interested in students who have morning availability, computer skills, or are interested in developing skills in advertising, marketing, or public relations. You may apply by completing an application. We are FULL for Fall 2023 and Spring 2024"
  },
  {
    "objectID": "who-we-are.html#lab-director",
    "href": "who-we-are.html#lab-director",
    "title": "People",
    "section": "Lab Director",
    "text": "Lab Director\n\n\n\n\n\n\n\n\nRick O. Gilmore is Professor of Psychology, a Huck Institute of the Life Sciences faculty member, and an Associate of the Institute for Cyberscience. He earned his bachelor’s degree magna cum laude in Cognitive Science from Brown University, and master’s and doctoral degrees in Psychology from Carnegie Mellon University where he participated in the Center for the Neural Basis of Cognition (CNBC) training program in cognitive neuroscience. Gilmore’s research focuses on the development of visual perception and memory. He is particularly interested in the development of brain networks that enable perceivers to extract information about the layout of the environment, the shape of objects, and the speed and direction of self-movement from patterns of visual motion called optic flow. Gilmore is also keenly interested in developing tools and practices that make scientific research more open, transparent, and reproducible. He is co-founder and Co-Director of the Databrary.org data library, and is co-PI on the Play & Learning Across a Year (PLAY) Project. From 2008 to 2014, Gilmore served as the founding Director of Human Imaging at Penn State’s Social, Life, and Engineering Sciences Imaging Center (SLEIC). He has won the College of the Liberal Arts tenure-line faculty teaching award, leads the Open Data in Developmental Science (ODDS) initiative for the Penn State Child Study Center, and has had support for his research from the National Institutes of Health and the National Science Foundation.\nGilmore has served as president of the Centre Region Bicycle Coalition, the Acoustic Brew Concert Series, and the State College Community Theatre. An active radio amateur or ham (callsign W3TM), he is member of the Board of Directors of the Nittany Amateur Radio Club and is the faculty adviser and K3CR license trustee for the Penn State Amateur Radio Club.\nContact Information\n114 Moore Building Department of Psychology The Pennsylvania State University University Park, PA 16801 814-865-3664, voice  814-863-7002, fax\nrogilmore AT-SIGN psu DOT edu\nMeeting scheduler"
  },
  {
    "objectID": "who-we-are.html#current-staff",
    "href": "who-we-are.html#current-staff",
    "title": "People",
    "section": "Current Staff",
    "text": "Current Staff\n\nAndrea Seisler, Lab Manager\n\n\n\n\n\n\n\n\nAndrea R. Seisler is the Laboratory Manager of the Brain and Behavioral Development Laboratory directed by Dr. Rick O. Gilmore. She has also been the Support and Authorizations Specialist at Databrary since November 2016. She received her bachelor’s and master’s degree in Biomedical Engineering from The Catholic University of America. During her graduate studies, she was a recipient of the Clare Booth Luce Fellowship award.\nShe completed MRI based neuroscience and orthopedics research while working at The National Institutes of Health from 2001-2007. After her move to State College, she served as an IRB Compliance Coordinator for the Human Research Protection Program at Penn State and then moved on in 2009 to manage the Human Electrophysiology Facility located at the Social, Life, and Enginineering Sciences Imaging Center through 2014.\nShe is active in Scouts BSA as a Committee Member in Troop 245 and an Executive Board Member of the Juniata Valley Council, BSA. She completed her Wood Badge leadership training course in September 2020 and was a Troop Guide on staff in the Spring of 2022. She has been the Assistant Scoutmaster of Administration for National Youth Leadership Training since 2021. In addition she enjoys dancing ballet and teaching at Dance Academy.\nContact Information\n503 Moore Building Department of Psychology The Pennsylvania State University University Park, PA 16802 ars17 AT-SIGN psu DOT edu\n\n\n\n\n\n\nMolly Askin, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\nMolly Askin is a junior at the Pennsylvania State University and is from New Jersey. She is majoring in Psychology with the Neuroscience option with a minor in neuroscience. She is involved in campus through Greek life in her sorority Alpha Xi Delta. She is also involved in THON as an assistant THON chair which consists of helping with anything the other THON chairs need help with as well as helping to raise money for THON. She is interested in pursuing her education further and eventually getting her PhD in neuropsychology with hopes to eventually study patients with Alzheimer’s and dementia.\n\n\n\n\n\nBruna Baldivieso, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrianna Beamer, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\nBrianna Beamer is a Junior at Penn State University studying Psychology with a neuroscience focus. She works in the Gilmore Lab here at Penn State. She hopes to further her education and eventually earn a Ph.D. in Psychology to become a neuropsychologist. With this, she plans to help patients with damage in their central nervous system to help them to overcome the struggles they encounter. In Brianna’s free time, she enjoys baking, listening to music, and exploring the outdoors. A fun fact about Brianna is she is from Dallas, Texas!\n\n\n\n\n\nNicole Cruz, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\nNicole Cruz is a sophomore at Pennsylvania State University pursuing an undergraduate degree in Psychology with a Neuroscience focus. She intends to graduate in the spring of 2025 and continue her education by pursuing an MD and/or Ph.D. in Neuropsychology. She is interested in research on topics about neurological disorders like Alzheimer’s disease. She is now an undergraduate research assistant working with Dr. Gilmore in his Brain and Behavioral Dynamics lab Gilmore Lab at Penn State. In her free time, she enjoys listening and playing music, traveling, and cooking.\n\n\n\n\n\nJulia DiFulvio, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClara Eroles, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOriana Franco, Undergraduate Research Assistant\n\n\n\n\nOriana Franco is a Penn State University student, pursuing a psychology major. She is intended to graduate in the spring of 2026 and further her education by pursuing a Ph.D. in Neuroscience or Computer Science. Her hobbies consist of reading, hiking, running, and playing with her dog and cat. Oriana’s interest in developmental psychology has led her to find Dr. Gilmore’s lab and become a part of it. Her proficiency in English and Spanish opened many doors for her to communicate with many individuals without barriers. Oriana’s passion for helping people has put her on a path to further her knowledge on things such as mental illness, in the hopes of later on in her life being able to use that knowledge to guide others.\n\n\n\n\nMadison Gehringer, Undergraduate Research Assistant\n\n\n\n\nMadison Gehringer is a Senior at Penn State pursuing an undergraduate degree in psychology with a focus in neuroscience as well as a minor in biology. Madison is interested in studying brain damage and mental illness, her interest in the brain led her to become apart of Dr. Gilmore’s lab. Madison is currently working on the PLAY project as lead data collector for Penn State. She is a member of the National Society of Leadership and Success at Penn State. In her free time she enjoys baking, drawing and listening to music. Madison is an avid animal lover and when she is not at Penn State she works as an animal technician at the Montgomery County SPCA Perkiomenville location.\n\n\n\n\nPeter Huang, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\nPeter is a senior student majoring in Biology with a focus on neuroscience option, he is currently participating in Legacy project in Gilmore Lab at Penn State. He is interested in how our brain works at neuron levels, especially visual perception. Peter plans to continue pursuing a Ph.D. in neuroscience after graduation from Penn State.\n\n\n\n\nYinghe Liu, Undergraduate Research Assistant\n\n\n\n\n\n\n\n\nLiu is a senior undergraduate majoring in Psychology with a minor in Human Development and Family Study. Currently, Liu is working on improving the guidance manual for Databrary. His academic journey has been defined by a deep interest in understanding the development of decision-making mechanism with a focus on cognitive flexibility. He is also planning on a post-undergraduate education after graduation. Outside of his academic interest, Liu is an enthusiastic player of the game of Go, a complex board game that has significantly shaped his perspective on human intelligence.\n\n\n\n\nSydney (Belle) Peterson, Undergraduate Research Assistant\n\n\n\n\nBelle Peterson is a senior Biobehavioral Health Major, with minors in Global Health and Diversity and Inclusion in Health and Human Development. Belle is currently preparing to apply to medical school, with the goal of eventually becoming a Pediatrician and working with underserved pediatric populations, both domestically and abroad. Belle is passionate about the intersections between physiological and psychological health, and has had the opportunity to pursue this interest during her time in the Gilmore Lab, as well as through the founding of her artificial intelligence based start-up, Apoio, which focuses on improving the intake process for mental health providers in rural/remote regions. Belle is also involved with Alpha Phi Omega and Remote Area Medical, which are both student-run service organizations on campus. In her free time, Belle enjoys swimming, baking, and trying new coffee shops."
  },
  {
    "objectID": "who-we-are.html#recent-alumni",
    "href": "who-we-are.html#recent-alumni",
    "title": "People",
    "section": "Recent Alumni",
    "text": "Recent Alumni\n\nYsa Fernandez\nYiming Qian, Ph.D.\nCecelia Petrarca\nKayla Moninger\nKavya Jhaveri\nBowen Deng\nAnjali Jivan\nMaureen Burke\nSara Delmoral\nKymberle Shields\nShahir Rayes\nMichelle Mendez\nRachel Chang\nAnna Capria\nEmily Herman\nChelsea Davis\nSandy Rayes\nLuka Kelly\nAmar Bhatia\nZhichun Zhao\nSarah Shahriar\nAshton Dluzneski\nAlyssa Pandos\n\nCharmi Mehta\n\nMichael Dexheimer\nHifzah Malik\nRaya Willoughby\nKatie Torres\nShivani Patel\nMichael O’Neill\nDaved Fared\nAuburn Lattanzio, Graduate student, Villanova University\nMichelle Shade\nSam Pai\nJun Oh, Apprentice Ruby on Rails Developer, Launch Academy, Inc.\nAmanda Thomas, Ph.D.\nWilliam Adamiak\nShivam Vedak, MBA, MD\nDan Elbich, Graduate student, Penn State\nJeremy Fesi, Ph.D., Research Analyst, U.S. Marine Corps\nLorena Gonzalez, Graduate student, Penn State\nRicky Groner, IT Support Specialist, Huck Institutes of the Life Sciences, Penn State\nKen Hwang, Consultant, Anexinet\nMatthew Lee, MBA student, Penn State\nPatricia Jones, Optometry student, Pennsylvania College of Optometry"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "Rick O. Gilmore is Associate Professor of Psychology, a Huck Institute of the Life Sciences faculty member, and an Associate of the Institute for Cyberscience. He earned his bachelor’s degree magna cum laude in Cognitive Science from Brown University, and master’s and doctoral degrees in Psychology from Carnegie Mellon University where he participated in the Center for the Neural Basis of Cognition (CNBC) training program in cognitive neuroscience. Gilmore’s research focuses on the development of visual perception and memory. He is particularly interested in the development of brain networks that enable perceivers to extract information about the layout of the environment, the shape of objects, and the speed and direction of self-movement from patterns of visual motion called optic flow. Gilmore is also keenly interested in developing tools and practices that make scientific research more open, transparent, and reproducible. He is co-founder and Co-Director of the Databrary.org data library.\nFrom 2008 to 2014, Gilmore served as the founding Director of Human Imaging at Penn State’s Social, Life, and Engineering Sciences Imaging Center (SLEIC). He has won the College of the Liberal Arts tenure-line faculty teaching award, leads the Human Developmental Neuroscience Initiative for the Child Study Center, and has had support for his research from the National Institutes of Health and the National Science Foundation. Gilmore has served as president of the Centre Region Bicycle Coalition, the Acoustic Brew Concert Series, and the State College Community Theatre. He recently joined the board of the Nittany Amateur Radio Club (NARC), and serves as faculty adviser (and K3CR license trustee) for the Penn State Amateur Radio Club."
  },
  {
    "objectID": "about.html#gilmore-bio",
    "href": "about.html#gilmore-bio",
    "title": "about",
    "section": "",
    "text": "Rick O. Gilmore is Associate Professor of Psychology, a Huck Institute of the Life Sciences faculty member, and an Associate of the Institute for Cyberscience. He earned his bachelor’s degree magna cum laude in Cognitive Science from Brown University, and master’s and doctoral degrees in Psychology from Carnegie Mellon University where he participated in the Center for the Neural Basis of Cognition (CNBC) training program in cognitive neuroscience. Gilmore’s research focuses on the development of visual perception and memory. He is particularly interested in the development of brain networks that enable perceivers to extract information about the layout of the environment, the shape of objects, and the speed and direction of self-movement from patterns of visual motion called optic flow. Gilmore is also keenly interested in developing tools and practices that make scientific research more open, transparent, and reproducible. He is co-founder and Co-Director of the Databrary.org data library.\nFrom 2008 to 2014, Gilmore served as the founding Director of Human Imaging at Penn State’s Social, Life, and Engineering Sciences Imaging Center (SLEIC). He has won the College of the Liberal Arts tenure-line faculty teaching award, leads the Human Developmental Neuroscience Initiative for the Child Study Center, and has had support for his research from the National Institutes of Health and the National Science Foundation. Gilmore has served as president of the Centre Region Bicycle Coalition, the Acoustic Brew Concert Series, and the State College Community Theatre. He recently joined the board of the Nittany Amateur Radio Club (NARC), and serves as faculty adviser (and K3CR license trustee) for the Penn State Amateur Radio Club."
  },
  {
    "objectID": "about.html#contact-information",
    "href": "about.html#contact-information",
    "title": "about",
    "section": "Contact Information",
    "text": "Contact Information\n\n114 Moore Building Department of Psychology The Pennsylvania State University University Park, PA 16801 814-865-3664, voice  814-863-7002, fax\nrogilmore AT-SIGN psu DOT edu"
  },
  {
    "objectID": "students.html",
    "href": "students.html",
    "title": "For Students",
    "section": "",
    "text": "Rick O. Gilmore is Associate Professor of Psychology, a Huck Institute of the Life Sciences faculty member, and an Associate of the Institute for Cyberscience. He earned his bachelor’s degree magna cum laude in Cognitive Science from Brown University, and master’s and doctoral degrees in Psychology from Carnegie Mellon University where he participated in the Center for the Neural Basis of Cognition (CNBC) training program in cognitive neuroscience. Gilmore’s research focuses on the development of visual perception and memory. He is particularly interested in the development of brain networks that enable perceivers to extract information about the layout of the environment, the shape of objects, and the speed and direction of self-movement from patterns of visual motion called optic flow. Gilmore is also keenly interested in developing tools and practices that make scientific research more open, transparent, and reproducible. He is co-founder and Co-Director of the Databrary.org data library.\nFrom 2008 to 2014, Gilmore served as the founding Director of Human Imaging at Penn State’s Social, Life, and Engineering Sciences Imaging Center (SLEIC). He has won the College of the Liberal Arts tenure-line faculty teaching award, leads the Human Developmental Neuroscience Initiative for the Child Study Center, and has had support for his research from the National Institutes of Health and the National Science Foundation. Gilmore has served as president of the Centre Region Bicycle Coalition, the Acoustic Brew Concert Series, and the State College Community Theatre."
  },
  {
    "objectID": "students.html#gilmore-bio",
    "href": "students.html#gilmore-bio",
    "title": "For Students",
    "section": "",
    "text": "Rick O. Gilmore is Associate Professor of Psychology, a Huck Institute of the Life Sciences faculty member, and an Associate of the Institute for Cyberscience. He earned his bachelor’s degree magna cum laude in Cognitive Science from Brown University, and master’s and doctoral degrees in Psychology from Carnegie Mellon University where he participated in the Center for the Neural Basis of Cognition (CNBC) training program in cognitive neuroscience. Gilmore’s research focuses on the development of visual perception and memory. He is particularly interested in the development of brain networks that enable perceivers to extract information about the layout of the environment, the shape of objects, and the speed and direction of self-movement from patterns of visual motion called optic flow. Gilmore is also keenly interested in developing tools and practices that make scientific research more open, transparent, and reproducible. He is co-founder and Co-Director of the Databrary.org data library.\nFrom 2008 to 2014, Gilmore served as the founding Director of Human Imaging at Penn State’s Social, Life, and Engineering Sciences Imaging Center (SLEIC). He has won the College of the Liberal Arts tenure-line faculty teaching award, leads the Human Developmental Neuroscience Initiative for the Child Study Center, and has had support for his research from the National Institutes of Health and the National Science Foundation. Gilmore has served as president of the Centre Region Bicycle Coalition, the Acoustic Brew Concert Series, and the State College Community Theatre."
  },
  {
    "objectID": "students.html#contact-information",
    "href": "students.html#contact-information",
    "title": "For Students",
    "section": "Contact Information",
    "text": "Contact Information\n\n114 Moore Building Department of Psychology The Pennsylvania State University University Park, PA 16801 814-865-3664, voice  814-863-7002, fax\nrogilmore AT-SIGN psu DOT edu\nhttps://www.personal.psu.edu/rog1"
  },
  {
    "objectID": "students.html#current-staff",
    "href": "students.html#current-staff",
    "title": "For Students",
    "section": "Current Staff",
    "text": "Current Staff\n\nAndrea Seisler, Lab Manager\nAndrea R. Seisler is the Laboratory Manager of the Brain Development Laboratory directed by Dr. Rick O. Gilmore. She received her bachelor’s and master’s degree in Biomedical Engineering from The Catholic University of America. During her graduate studies, she was a recipient of the Clare Booth Luce Fellowship award.\nShe completed MRI based neuroscience and orthopedics research while working at The National Institutes of Health from 2001-2007. After her move to State College, she served as an IRB Compliance Coordinator for the Office for Research Protections at Penn State and then moved on to manage the Human Electrophysiology Facility located at the Social, Life, and Enginineering Sciences Imaging Center through 2014.\n\nContact Information\n\n503 Moore Building Department of Psychology The Pennsylvania State University University Park, PA 16802 ars17 AT-SIGN psu DOT edu\n\n\n\n\nYiming Qian\nYiming is the graduate student in the Department of Psychology at PSU. Her research interests is exploring the development of brain networks from early childhood to adulthood, using neuroimaging tools. She is also interested in the mechanism of visual motion.\nBesides research activities, Yiming enjoys reading, cooking, gardening, hiking and fishing. She is a big fan of operas and musicals.\n\n\nSarah Shahriar\nSarah is a junior majoring in Psychology with a concentration in Neuroscience. She hopes to pursue a medical degree after studying at Penn State University and hopes to practice as a psychiatrist in the future.\nSarah is originally from Hershey, PA and enjoys spending her time volunteering at Penn State Hershey Medical Center Children’s Hospital within the Ronald McDonald charities."
  },
  {
    "objectID": "students.html#recent-alumni",
    "href": "students.html#recent-alumni",
    "title": "For Students",
    "section": "Recent Alumni",
    "text": "Recent Alumni\n\nAlyssa Pandos\nCharmi Mehta\nRaya Willoughby\nKatie Torres\nShivani Patel\nMichael O’Neill, Graduate student, PSU\nDaved Fared\nAuburn Lattanzio\nMichelle Shade\nSam Pai\nJun Oh, Apprentice Ruby on Rails Developer, Launch Academy, Inc.\nAmanda Thomas, Postdoctoral researcher, Swarthmore\nWilliam Adamiak, NIH IRTA\nShivam Vedak, Medical student\nDan Elbich, Graduate student, Penn State\nJeremy Fesi, Ph.D., US Marine Corps Research\nLorena Gonzalez, Graduate student, Penn State\nRicky Groner, IT Support Specialist, Huck Institutes of the Life Sciences, Penn State\nKen Hwang, Consultant, Anexinet\nMatthew Lee, MBA student, Penn State\nPatricia Jones, Optometry student, Pennsylvania College of Optometry"
  },
  {
    "objectID": "parents.html",
    "href": "parents.html",
    "title": "parents",
    "section": "",
    "text": "Some parents are surprised to learn how much we can learn from studies of infants and children. Dr. Gilmore has been conducting research with infants and children for more than 20 years, and he has two daughters of his own who have been regular participants in research studies. The Penn State Brain and Behavioral Dynamics Lab works very hard to ensure that you and your child will be safe and comfortable at all times and that everyone enjoys their visit to the lab. This page is designed to help parents prepare for a visit. If you have a question this page does not answer, please email (rogilmore@psu.edu) or call (814-865-3664) Dr. Gilmore.\n\n\n\n\nMost of our studies are conducted at Chandlee Laboratory on the main Penn State University Park campus in the Human Electrophysiology Laboratory (HEF). The HEF has parking set aside for research participants. We will give you directions to Chandlee Lab, and will make arrangements to meet you before your appointment and guide you to the parking spot. Here is a map that shows how to enter campus and provides directions to Chandlee. When you stop at the Parking Kiosk, you should tell the attendant that you are “here for a research study at the imaging center in Chandlee Laboratory.”\n\n\n\nMost appointments take about 45 min to an hour from start to finish. If we think we will go longer than that, we will tell you in advance.\n\n\n\nSome studies involve more than one visit. Others involve just a single visit. We will tell you in advance what the study requires. Sometimes, we may ask you to return if things have either gone especially well, or if we have made a mistake of some kind. You are under no obligation to participate, but we find that most families are happy to come back if they can make time in their schedule.\n\n\n\nYou and your child are in charge. If your child is unhappy about being in the study, we will stop. No questions asked."
  },
  {
    "objectID": "parents.html#frequently-asked-questions-faqs",
    "href": "parents.html#frequently-asked-questions-faqs",
    "title": "parents",
    "section": "",
    "text": "Most of our studies are conducted at Chandlee Laboratory on the main Penn State University Park campus in the Human Electrophysiology Laboratory (HEF). The HEF has parking set aside for research participants. We will give you directions to Chandlee Lab, and will make arrangements to meet you before your appointment and guide you to the parking spot. Here is a map that shows how to enter campus and provides directions to Chandlee. When you stop at the Parking Kiosk, you should tell the attendant that you are “here for a research study at the imaging center in Chandlee Laboratory.”\n\n\n\nMost appointments take about 45 min to an hour from start to finish. If we think we will go longer than that, we will tell you in advance.\n\n\n\nSome studies involve more than one visit. Others involve just a single visit. We will tell you in advance what the study requires. Sometimes, we may ask you to return if things have either gone especially well, or if we have made a mistake of some kind. You are under no obligation to participate, but we find that most families are happy to come back if they can make time in their schedule.\n\n\n\nYou and your child are in charge. If your child is unhappy about being in the study, we will stop. No questions asked."
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "",
    "text": "Discuss:\nLeonard, J. A., Lee, Y., & Schulz, L. E. (2017). Infants make more attempts to achieve a goal when they see adults persist. Science, 357(6357), 1290–1294. Retrieved from http://dx.doi.org/10.1126/science.aan2317."
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html#purpose",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html#purpose",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "",
    "text": "Discuss:\nLeonard, J. A., Lee, Y., & Schulz, L. E. (2017). Infants make more attempts to achieve a goal when they see adults persist. Science, 357(6357), 1290–1294. Retrieved from http://dx.doi.org/10.1126/science.aan2317."
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html#video-exemplar",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html#video-exemplar",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "Video exemplar",
    "text": "Video exemplar\n(tried to embed, but this only works sporadically.)\nhttp://science.sciencemag.org/highwire/filestream/699641/field_highwire_adjunct_files/1/aan2317s1.mp4"
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html#figures",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html#figures",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "Figures",
    "text": "Figures"
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html#methods-info-from-supplementary-materials",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html#methods-info-from-supplementary-materials",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "Methods info from supplementary materials",
    "text": "Methods info from supplementary materials\n\n“Button presses were operationalized as a hand pushing down the button. Button presses were coded from videotape by two coders blind to hypotheses and condition (inter-rater reliability \\(r = .99, p &lt; .001\\)). Data from a single coder was used for analyses but all results held with the second coder’s data. Coders agreed with the experimenter’s judgment on the termination of the experiment 100% of the time.”\n\n(Supplement, p. 2)\n\n\n“Additionally, a coder blind to condition and hypotheses coded the tapes for potential confounds. No difference was found across the conditions for whether the parent talked to the child (\\(\\chi^2 (2, N=102)=1.03\\), \\(p = .60\\)), parents’ proximity to the infant (as distance in inches, \\(H(2) = 4.32\\), \\(p = .12\\)), and parents’ encouragement to the infant (\\(\\chi^2 (2, N = 102) = 5.56\\), \\(p = .06\\)). Additionally, because the experimenter might have conveyed more enthusiasm in handing the toy to the child in the Effort than the No Effort condition, a second coder rated the experimenter’s enthusiasm at the start of the test trial on a Likert scale, blind to conditions (\\(W = 525\\), \\(p = .50\\)).”\n\n(Supplement, p. 2)"
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html#questions-cheers-lamentations",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html#questions-cheers-lamentations",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "Questions, cheers, & lamentations",
    "text": "Questions, cheers, & lamentations\n\nQuestions\n\nCould ‘effort’ be based on personal qualities of child?\nDifferences in environment (noise, what parent did, etc.)?\nWhat do parents & siblings do (for work, at home)?\nWould parent as demonstrator elicit stronger responses from kid?\nHow does child’s attention span affect outcome?\nIndividual differences in child’s interest in the toy?\n\n\n\nCheers\n\nPreregistration of replication\nShow video exemplars\nShared data and analysis scripts."
  },
  {
    "objectID": "lab-mtgs/leonard-lee-schultz-2017.html#lamentations",
    "href": "lab-mtgs/leonard-lee-schultz-2017.html#lamentations",
    "title": "Leonard, Lee, & Schultz 2017",
    "section": "Lamentations",
    "text": "Lamentations\n\nPlots don’t show individual responses (but we could fix with data file)\nFocus only on button pressing, lots of other behaviors that might have distinguished groups\nCould share videos of all participants on Databrary so other researchers could follow up\nScience article space limitations causes important details to be ‘buried’ in teh supplementary materials"
  },
  {
    "objectID": "lab-meetings.html",
    "href": "lab-meetings.html",
    "title": "lab-meetings",
    "section": "",
    "text": "For the Fall 2023 Semester, we will meet on Tuesdays 8:00-8:50 am in room 350 Moore."
  },
  {
    "objectID": "lab-meetings.html#goals",
    "href": "lab-meetings.html#goals",
    "title": "lab-meetings",
    "section": "Goals",
    "text": "Goals\n\nData science\n\nLearn R on Datacamp\nBegin by creating or updating your a brief biography for the Who we are page on the lab website.\n\nStart preparing for presentations in Spring 2024\n\nTrain on poster template for R posterdown\nSubmit abstracts for poster presentation:\nUndergraduate Research Exhibition\nPsi Chi Research Conference\n\nLaunch new projects\n\nPLAY\n\nData collection\nLocomotion coding\n\nLegacy: Visual Acuity\nMigrate lab site to Quarto\n\nReinvigorate old projects\n\nDatabrary tagging\nDatabrary User Guide\nTesting and documenting databraryr package, and the Databrary Analytics\nMotion meta-analysis\n\nFuture readings:\n\nYiming’s PhD paper and paper reviews"
  },
  {
    "objectID": "lab-meetings.html#fall-2023",
    "href": "lab-meetings.html#fall-2023",
    "title": "lab-meetings",
    "section": "Fall 2023",
    "text": "Fall 2023"
  },
  {
    "objectID": "lab-meetings.html#tuesday-october-10-2023",
    "href": "lab-meetings.html#tuesday-october-10-2023",
    "title": "lab-meetings",
    "section": "Tuesday, October 10, 2023",
    "text": "Tuesday, October 10, 2023\n\nProject updates/work session\n\nLegacy Project: Visual Acuity. update (Rick, Brianna, Julia, Nicole, Peter)\n\nUsing R, R Markdown & Quarto (Rick & Andrea)\n\nPlanning\n\nGoals\nAre data sensitive or not\n\nCreate repo\nCreate RStudio project\nCreate stub site/documents\nOn data page\n\nPurpose\nGathering\nCleaning\nVisualization\n\nCommit (& usually push)\n\n\n\nTuesday, October 3, 2023\nNo lab meeting\n\n\nTuesday, September 26, 2023, 350 Moore\n\nProject updates\n\nPLAY update (Madison, Andrea, Belle, Oriana)\nLegacy Project: Visual Acuity. update (Rick, Brianna, Julia, Nicole, Peter)\nDatabrary Guide project update (Andrea, Liu)\n\n\n\n\nTuesday, September 19, 2023, 350 Moore\n\nLooking for:\n\nWeb site master\ndatabraryr package tester and help with documentation.\nSign-up for Hypothes.is\n\nFuture meetings\n\nReadings related to PLAY, visual acuity project, Databrary\n\nPeter will look at: Teller, D. Y., McDonald, M. A., Preston, K., Sebris, S. L. & Dobson, V. (1986). Assessment of visual acuity in infants and children: The acuity card procedure. Developmental Medicine and Child Neurology, 28(6), 779–789. As candidate for reading as a group. https://doi.org/10.1111/j.1469-8749.1986.tb03932.x\n\nWork sessions on using Quarto and R Studio.\nLearning Mermaid and Graphviz tools from Quarto.\n\n\n\n\nTuesday, September 12, 2023, 350 Moore\n\nWhat is PLAY? (Madison)\nIntroducing the Legacy Project: Visual Acuity (Rick)\n\n\n\nTuesday, September 5, 2023, 350 Moore\n\nAssigning work teams (Andrea)\nWatch\n\nNYU Health Sciences Library. (2013, 13. November). Data Sharing and Management Snafu in 3 Short Acts (Higher Quality). Youtube. https://www.youtube.com/watch?v=66oNv_DJuPc\n\nDiscuss project team assignments (Rick)\n\n\n\nTuesday, 8/29/2023, 350 Moore\n\nIntroductions\nOrientation to Fall 2023 lab priorities (Rick)\n\nPlay & Learning Across a Year (PLAY) Project, PLAY site, Parent site, KoBoToolbox Surveys\nLegacy Project, especially Visual Acuity\nDatabrary, especially the Databrary Guide, the databraryr package, and the Databrary Analytics.\nRefreshing internal resources, especially the lab website and our lab protocols site.\n\nOnboarding and Training and orientation (Andrea)\nSchedule"
  },
  {
    "objectID": "lab-meetings.html#previous-meeting-notes",
    "href": "lab-meetings.html#previous-meeting-notes",
    "title": "lab-meetings",
    "section": "Previous meeting notes",
    "text": "Previous meeting notes\nNotes from previous semesters"
  },
  {
    "objectID": "lab-meetings.html#helpful-links",
    "href": "lab-meetings.html#helpful-links",
    "title": "lab-meetings",
    "section": "Helpful Links",
    "text": "Helpful Links\n\nGlobal Protect Instructions for Mac and Windows \nClick to login to Datacamp\nHow to take screen shots for Mac and Windows\nDatabrary"
  },
  {
    "objectID": "posts/lab-mtg-2023-10-10.html",
    "href": "posts/lab-mtg-2023-10-10.html",
    "title": "Lab meeting: 2023-10-10",
    "section": "",
    "text": "Datasaurus dozen\n\n\nThe visual acuity project team led a discussion about the draft protocol.\nRick and Andrea led a how-to session based on some reaction time data Andrea collected in her son Alex’s class last year. We will discuss how to plan a data visualization and analysis project like this in a way that “bakes-in” reproducible workflows from the very beginning."
  },
  {
    "objectID": "posts/new-site.html",
    "href": "posts/new-site.html",
    "title": "New website!",
    "section": "",
    "text": "Welcome to our new website. The old site was built in R Markdown. The new one is built in Quarto. We hope you like the new look and feel."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "research",
    "section": "",
    "text": "The social, behavioral, and neural sciences face more difficult scientific challenges than any other field has faced before. Open, transparent, and reproducible scientific practices are essential for accelerating discovery in these fields. My colleagues and I are developing policies for the ethical and secure sharing of personal data and technologies to allow the analysis and sharing of these data for scientific and educational purposes.\nPublications\nSoska, K.C., Xu, M., Gonzalez, S.L., Herzberg, O., Tamis-LeMonda, C.S., Gilmore, R.O., & Adolph, K.E. (2021). (Hyper)active data curation: A video case study from behavioral science. Journal of eScience Librarianship, 10(3), e1208. https://doi.org/10.7191/jeslib.2021.1208.\nGilmore, R.O., & Qian, Y. (2021). An open developmental science will be more rigorous, robust, and impactful. Infant and Child Development. https://doi.org/10.1002/icd.2254.\nGilmore, R.O., Xu, M., & Adolph, K.E. (2021). Data sharing. In Panecker, S. & Stanley, B. (Eds.), Handbook of Research Ethics in Psychological Science, APA Press, Washington, DC. PDF.\nGilmore, R.O., Cole, P.M., van Aken, M.A.G., Verma S., & Worthman, C.M. (2020). Advancing scientific integrity, transparency, and openness in child development research: Challenges and possible solutions. Child Development Perspectives, 14(1), 9-14. http://dx.doi.org/10.1111/cdep.12360\nOssmy O., Gilmore R.O., Adolph K.E. (2020) AutoViDev: A Computer-Vision Framework to Enhance and Accelerate Research in Human Development. In: Arai K., Kapoor S. (eds) Advances in Computer Vision. CVC 2019. Advances in Intelligent Systems and Computing, vol 944. Springer, Cham. doi: 10.1007/978-3-030-17798-0_14\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2018). Practical solutions for sharing data and materials From psychological research. Advances in Methods and Practices in Psychological Science, SAGE Publications Inc. Retrieved from https://doi.org/10.1177/2515245917746500. OSF preprint.\nGilmore, R.O., Diaz, M.T., Wyble, B.A., & Yarkoni, T. (2017). Progress toward openness, transparency, and reproducibility in cognitive neuroscience. Annals of the New York Academy of Sciences, 1396, 5–18. doi: 10.1111/nyas.13325.\nGilmore, R.O. (2016). From big data to deep insight in developmental science. Wiley Interdisciplinary Reviews Cognitive Science. DOI: 10.1002/wcs.1379.\nPresentations\nGilmore, R.O., Wham, B., & Zinoble, R. (2021, October). Getting ahead of the curve: Responding to emerging data management plan requirements. Presentation as part of the Open Data & Developmental Science (ODDS) Initiative. slides.\nGilmore, R.O. (2021, April). Invited panel presentation to “Changing the Culture of Data Management and Sharing: A Workshop”, National Academies of Science, Engineering, and Medicine.\nGilmore, R.O. (2021, January). “The Human Behaviorome Project”, Invited presentation to the Networking and Information Technology Research and Development (NITRD) workshop on the Future of Federally Supported Data Repositories.\nGilmore, R.O. (2020, September). Invited presentation at FLUX Preconference Workshop on Infant Neuroimaging.\nGilmore, R.O. (2020, May 23). Invited symposium presentation on Open Science for Different Methodological Approaches in Psychology, 2020 meeting of the Association for Psychological Science, Chicago, IL. Cancelled.\nGilmore, R.O. (2020, April 15). The open science revolution: A report from the front lines. Talk given in the Penn State Data Studies Group. slides.\nGilmore, R.O. (2020, February 21). Research computing in child development research. Invited talk to the Penn State Child Study Center. slides.\nGilmore, R.O. (2019, June 3). Making cognitive science even better. Talk given at the James S. McDonnell Foundation retreat. slides.\nGilmore, R.O. (2019, March 28). The whole elephant. Talk given at the Penn State Center for Neural Engineering (CNE) colloquium series. slides.\nGilmore, R.O., Gennetian, L., Kalish, C., Tamis-LeMonda, C.T., & Worthman, C. (2019, March). What SRCD is doing about open science: A conversation hour. Presentation at the 2019 Society for Research in Child Development (SRCD) meeting, Baltimore, MD. slides.\nGilmore, R.O. (2019, January). An open science of human health & behavior. Invited talk given to the College of Health & Human Development. HTML slides.\nGilmore, R.O. (2018, October). The Open Data and Developmental Science (ODDS) Initiative. Invited talk at the Penn State Child Study Center (CSC). HTML slides.\nGilmore, R.O. (2018, October). The promise of open developmental science. Invited talk at the SRCD Conference on the Use of Secondary and Open Source Data in Developmental Science. Phoenix, AZ. HTML slides\nGilmore, R.O. (2018, September). Big data behavioral science: From micro- to macro-scale. Annual Conference of the Federal Statistical Research Data Centers. University Park, PA. HTML slides\nGilmore, R.O. (2018, May). Open, says me: Practical solutions for sharing data and materials. Invited talk at the Association for Psychological Science 2018 meeting. San Francisco, CA. HTML slides\nGilmore, R.O. (2017, September 29). Data sharing, research ethics, & scientific reproducibility. Talk at the Scholarship and Research Integrity (SARI) workshop series, Penn State. HTML slides.\nGilmore, R.O. (2017, September 7). Reproducibility in computationally intensive behavioral research. Talk at the ACI-ICS seminar series, Penn State. HTML slides.\nSoftware\ndatabraryapi, an R package for Databrary. https://github.com/PLAY-behaviorome/databraryapi.\ndatabrarypy, a Python package for Databrary. https://github.com/PLAY-behaviorome/databrarypy.\nRoles\n\nChaired Society for Research in Child Development (SRCD) Task Force on Scientific Integrity and Openness (2018-2019) that drafted a Policy on Scientific Integrity, Transparency, and Openness and author guidelines.\nLead the Open Data & Developmental Science (ODDS) initiative for the Penn State Child Study Center.\nCo-lead R Bootcamp workshop for Penn State graduate students, postdocs, and faculty. 2019 course site, 2018 course site.\n\nCollaborators\n\nKaren Adolph, New York University, Co-Principal Investigator and Project Director.\nOri Ossmy, New York University\nJeff Spies, 221b.io\n\n\nThe Databrary Project aims to increase scientific transparency and accelerate discovery in developmental science by building infrastructure for researchers to share video data and related meta-data. The project has five specific aims:\n\nCreate a web-based data library for sharing and preserving video data and associated meta-data.\nCreate participant and contributor/user standards that enable open sharing of video data while limiting access to authorized users to ensure participant confidentiality.\nExpand the free, open source video coding software, Datavyu to enable coding, exploring, and analyzing video data.\nBuild a data management system to support data sharing within labs, among collaborators, and in the Databrary repository.\nTransform the culture of developmental science by building a community of researchers committed to open video data sharing.\n\nDatabrary is an open-source software project. Penn State is one of the major “nodes”, with a large number of authorized users.\nPublications\nGilmore, R.O., Xu, M., & Adolph, K.E. (2021). Data sharing. In Panecker, S. & Stanley, B. (Eds.), Handbook of Research Ethics in Psychological Science, APA Press, Washington, DC.\nGilmore, R. O. & Adolph, K. E. (2019). Open sharing of research video: Breaking down the boundaries of the research team. In , K. L. Hall, A. L. Vogel, & R. T. Croyle (Eds.), Strategies for team science success: Handbook of evidence-based principles for cross-disciplinary science and practical lessons learned from health researchers. Cham: Springer, pp. 575-583.\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2018). Practical solutions for sharing data and materials From psychological research. Advances in Methods and Practices in Psychological Science, SAGE Publications Inc. Retrieved from https://doi.org/10.1177/2515245917746500. OSF preprint.\nAdolph, K.E., Gilmore, R.O., & Kennedy, J.L. (2017, October). Video data and documentation will improve psychological science. Psychological Science Agenda. http://www.apa.org/science/about/psa/2017/10/video-data.aspx\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2017, September 7). Practical solutions for the ethical sharing of identifiable research data. Retrieved from http://psyarxiv.com/kew8u.\nGilmore, R.O. & Adolph, K.E. (2017). Video can make behavioural science more reproducible. Nature Human Behaviour. doi:10.1038/s41562-017-0128.\nGilmore, R.O., & Adolph, K.E. (2017, February 6). Video can make science more open, transparent, robust, and reproducible. Retrieved from http://osf.io/3kvp7.\nGilmore, R.O., Adolph, K.E., Millman, D.S. (2016). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. PDF of paper.\nGilmore, R.O., Adolph, K.E., Millman, D.S., & Gordon, A. (2016). Transforming education research through open video data sharing. Advances in Engineering Education, 5(2). HTML.\nGordon, A., Millman, D.S., Steiger, L., Adolph, K.E., & Gilmore, R.O. (2015). Researcher-library collaborations: Data repositories as a service for researchers. Journal of Librarianship and Scholarly Communication. doi:10.7710/2162-3309.1238.\nAdolph, K.E., Gilmore, R.O., Freeman, C., Sanderson, P., & Millman, D. (2012). Toward Open Behavioral Science, Psychological Inquiry: An International Journal for the Advancement of Psychological Theory, 23(3), 244-247. doi:10.1080/1047840X.2012.705133.\nPresentations\nGilmore, R.O. (2019, June 6). Video as data and documentation. Workshop at a Symposium Honoring Brian MacWhinney, Carnegie Mellon University, Pittsburgh, PA. slides.\nGilmore, R.O. (2018, October). Sharing video data. Data blitz talk at the SRCD Conference on the Use of Secondary and Open Source Data in Developmental Science. Phoenix, AZ. HTML slides\nGilmore, R.O., Adolph, K.E., & Seisler, A.S. (2018, October). Sharing nicely with others: Moving developmental scientists toward open data sharing. Poster presented at the SRCD Conference on the Use of Secondary and Open Source Data in Developmental Science. Phoenix, AZ. PDF.\nGilmore, R.O. (2018, April 25). Video as data and documentation. Talk in the Department of Communication Arts & Sciences, Penn State. HTML slides\nGilmore, R.O. (2018, February 14). The future of quantitative developmental science. Talk given at the Quantitative Developmental Methodology brown bag series. HTML slides.\nGilmore, R.O. (2018, January 31). Introducing Databrary. Talk given at the Penn State Software in the Humanities & Social Sciences workshop. HTML slides.\nGilmore, R.O. (2018, January 26). The Video DatAbservatory: A platform for behavioral discovery. Talk at the Pathways to Competence initiative meeting of the Penn State Child Study Center. HTML slides.\nGilmore, R.O. (2017, August 1). Video can improve the reproducibility of psychological science. Lightning talk at the Society for Improving Psychological Science meeting, Charlottesville, VA. HTML slides\nGilmore, R.O. (2017, July 31). Beyond physics envy: Toward a databservatory for human behavior. Lightning talk at the Society for Improving Psychological Science meeting, Charlottesville, VA. HTML slides.\nGilmore, R.O. & Nilsonne, G. (2017, July 30). IRBs and the ethical sharing of research data. Talk given at the Society for Improving Psychological Science meeting, Charlottesville, VA. HTML slides. OSF project.\nGilmore, R.O. (2017, July 26). Yes, we can. Invited panelist at the AERA Workshop on Data Sharing and Research Transparency at the Article Publishing Stage. HTML slides.\nGilmore, R.O. (2017, July 10). The reproducibility crisis in psychology & neuroscience. Talk given at the Penn State Data Reproducibility Bootcamp. HTML slides.\nAdolph, K.E., Binion, G. Gilmore, R.O., Oakes, L., & Vazire, S. (2017, April 6). Openness, replication, & data reuse in developmental science – unique challenges, existing resources, & what is still needed. Invited roundtable at the Society for Research in Child Development meeting, Austin, TX.\nGilmore, R.O. (2017, February 22). A Databservatory for human behavior. Talk given at the Cognitive Area Brown Bag. HTML slides.\nGilmore, R.O. (2017, January 31). An -ome of our own: Toward a more reproducible, robust, and insightful science of human behavior. Talk given to the Social Data Analytics (SoDA) 501 students. Penn State University. HTML slides\nGilmore, R.O. (2016, October). The future of big data in developmental science. Talk given at a meeting of the Penn State Child Study Center (CSC) faculty. HTML slides.\nGilmore, R.O. (2016, September). Donald Rumsfeld and the promise of a ‘big data’ science of human behavior. Talk given at a meeting of the Stochastic Modeling and Computational Statistics (SMACS) group, Department of Statistics. HTML slides.\nGilmore, R.O., Adolph, K.E., & Millman, D.S. (2016, August). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. HTML slides. PDF of paper.\nGilmore, R.O., Adolph, K.E., & Millman, D. (2016, May). Video doesn’t lie: Reproducible workflows with Databrary. Talk given at the NYU Data Science Center Symposium on Reproducibility. HTML slides\nGilmore, R.O., Adolph, K.E., Millman, D.S., Steiger, L., & Simon, D.A. (2015, May). Sharing displays and data from vision science research with Databrary. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. PDF.\nSimon, D.A., Gordon, A.S., Steiger, L., & Gilmore, R.O. (2015, June). Databrary: Enabling sharing and reuse of research video. Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries, Knoxville, TN. doi:10.1145/2756406.2756951\nRole\n\nServe as co-founder and co-director.\n\nCollaborators\n\nKaren Adolph, New York University, Co-Principal Investigator and Project Director.\nDavid Millman, New York University, Co-Investigator.\nJeff Spies, Consulting Chief Technology Officer, Databrary\n\nSupport\nThis project is supported by the U.S. National Science Foundation (NSF) Grant No. BCS-1238599, the Eunice Kennedy Shriver National Institute of Child Health and Human Development under Cooperative Agreement 1-U01-HD-076595-01, the Society for Research in Child Development, the LEGO Foundation, the Alfred P. Sloan Foundation, and the James S. McDonnell Foundation.\n\n\nThe Play & Learning Across a Year (PLAY) project serves as a model system for doing development science from a “big” data approach. Natural free play represents the foundation of infant learning, but we know little about how infants play, how play unfolds in real time and across development, and how individual and group differences promote infant learning and development through play. To answer these questions, the PLAY project will collect, code, and share 900 hours of video collected in the homes of children at 12, 18, and 24 months of age drawn from 30 sites across North America.\nThe aim of the project is to develop a new approach to developmental science that enables (1) “big” data science for researchers who would not otherwise have access; (2) a communal, low-cost means of collecting and coding data that retains the autonomy of individual labs; and (3) a plan for leveraging diverse expertise to address a common goal.\nPublications\nSoska, K.C., Xu, M., Gonzalez, S.L., Herzberg, O., Tamis-LeMonda, C.S., Gilmore, R.O., & Adolph, K.E. (2021). (Hyper)active data curation: A video case study from behavioral science. Journal of eScience Librarianship, 10(3), e1208. https://doi.org/10.7191/jeslib.2021.1208.\nPresentations\nGilmore, R.O., Jayaraman, S., Hassan, S., & Lingeman, J. (2020, July). Tools for reproducible developmental science. Poster to be presented at the 2020 International Congress on Infant Studies, Glasgow, Scotland.\nAdolph, K.E., Tamis-LeMonda, C., & Gilmore, R.O. (2016, December 16). Video-based communal data collection & coding: Advancing the science of infant learning & development. A workshop held at the Eunice Kennedy Shriver National Institute of Child Health and Human Development. Video Cast. Materials & data.\nMaterials\nGilmore, R.O. (2017). PLAY-behaviorome. Github code repository. Retrieved December 19, 2017 from https://github.com/PLAY-behaviorome/.\nAdolph, K., Tamis-LeMonda, C. & Gilmore, R.O. (2017). PLAY Pilot Data Collections. Databrary. Retrieved December 19, 2017 from https://nyu.databrary.org/volume/444.\nAdolph, K., Tamis-LeMonda, C. & Gilmore, R.O. (2016). PLAY Project: Materials. Databrary. Retrieved December 19, 2017 from https://nyu.databrary.org/volume/254.\nAdolph, K., Tamis-LeMonda, C. & Gilmore, R.O. (2016). PLAY Project: Webinar discussions on protocol and coding. Databrary. Retrieved December 19, 2017 from https://nyu.databrary.org/volume/232.\nRole\n\nServe as Co-PI and head of data science.\n\nCollaborators\n\nKaren Adolph, New York University, Co-Principal Investigator.\nCatherine Tamis-LeMonda, New York University, Co-Principal Investigator.\nKasey Soska, New York University, Scientific Director.\n\nSupport\nPLAY is supported by grants from the Office of the Director, National Institutes of Health, (OD), Eunice Kennedy Shriver National Institute for Child Health and Human Development (NICHD), the National Institute of Mental Health (NIMH), and the National Institute on Drug Abuse (NIDA) under R01HD094830-01, the LEGO Foundation, and the Alfred P. Sloan Foundation.\n\n\n\nPrevious research has shown that males and females differ on a number of psychological dimensions, including some basic aspects of visual processing. We are exploring the extent to which low-level visual dimensions of visual processing correlate with one another and with higher order characteristics like spatial cognition and hobby choices.\nRole\n\nCo-Investigator\n\nMaterials\n\nGitHub project\n\nCollaborators\n\nSheri Berenbaum, Penn State\nYiming Qian, Penn State\n\nPublications\nBerenbaum, S.A., Qian, Y., & Gilmore, R.O. (in prep). Vision contributes to sex differences in spatial cognition and activity interests.\nPresentations\n\n\n\nAI and computer vision tools are increasingly useful in basic and applied behavioral science. This project aims to provide a set of tools based on open source algorithms and models that empowers non-specialists to exploit advances in these areas.\nMaterials\n\nGitHub project\n\nRole\n\nPrincipal Investigator\n\nCollaborators\n\nDan Albohn, Penn State Department of Psychology\nKory Blose, Penn State Applied Research Lab\nStephen Fast, Penn State Applied Research Lab\nOri Ossmy, New York University\nDrew Polasky, Penn State Institute for Cyberscience\n\n\n\n\n \nVisual motion provides humans and animals with information about their own movement through 3D space and about the structure of the environment – the objects, surfaces, and other animals that it may contain. How the human brain processes complex motion information poses an as-yet unanswered question. This project focuses on characterizing how sensitivity to visual motion emerges in the developing human brain: how brain (EEG) responses to patterns of ego- and object motion emerge, how they develop from infancy through childhood into adulthood, how specific changes in cortical circuitry might account for the observed patterns, and how behavioral sensitivity to motion corresponds to neural activation. The studies compare brain responses and behavioral discrimination patterns in infants, children, and adults to the same types of ego- and object motion. The studies also involve an effort to measure or simulate the statistics of optic flow experienced by infant, child, and adult observers in complex, natural environments using computer vision methods.\nPublications\nQian, Y., Seisler, A.R., & Gilmore, R.O. (in press). Children’s sensitivity to optic flow-like visual motion differs from adults. Developmental Psychology. GitHub repository at https://github.com/gilmore-lab/sex-differences-in-motion-perception\nGilmore, R.O., Thomas, A.L., & Fesi, J.D (2016). Children’s brain responses to optic flow vary by pattern type and motion speed. PLoS ONE. doi: 10.1371/journal.pone.0157911. Materials on Databrary at http://doi.org/10.17910/B7QG6W.\nGilmore, R.O., Raudies, F., & Jayaraman, S. (2015). What Accounts for Developmental Shifts in Optic Flow Sensitivity? Proceedings of the IEEE International Conference on Development and Learning and Epigenetic Robotics. doi:10.1109/DEVLRN.2015.7345450. Materials on Databrary at doi:10.17910/B7988V.\nFesi, J.F., Thomas, A.L., & Gilmore, R.O. (2014). Cortical responses to optic flow and motion contrast across patterns and speeds. Vision Research, 100, 56–71. doi:10.1016/j.visres.2014.04.004. Materials on Databrary.\nRaudies, F. & Gilmore, R.O. (2014). Visual motion priors differ for infants and mothers. Neural Computation, 26(11), 2652-2668. doi:10.1162/NECO_a_00645.\nRaudies, F., Gilmore, R.O., Kretch, K.S., Franchak, J.M, & Adolph, K.E. (2012). Understanding the development of motion processing by characterizing optic flow experienced by infants and their mothers. Proceedings of the IEEE International Conference on Development and Learning. doi:10.1109/DevLrn.2012.6400584.\nPresentations\nGilmore, R.O. (2018, February 24). The development of perception for action. Data blitz talk at the Developmental Area graduate recruiting weekend. HTML slides.\nGilmore, R.O., Seisler, A., Shade, M., O’Neill, M. (2017, April). School-age children perceive fast radial optic flow in noise more accurately than slow linear flow. Poster presentation at the Society for Research in Child Development, Austin, TX. PDF. Databrary. GitHub.\nGilmore, R.O. (2017, February). Go with the flow: The development of behavioral sensitivity and brain responses to optic flow. Talk at Temple University. HTML slides. Markdown.\nGilmore, R.O., Fared, D.A., Dexheimer, M.G., & Seisler, A.R. (2016, November). The appearance and disappearance of visual forms defined by differential motion evokes distinctive EEG responses in school-age children. Presentation at the Society for Neuroscience meeting in San Diego, CA. PDF.\nGilmore, R.O. (2016, October). Go with the flow: The development of behavioral sensitivity and brain responses to optic flow. Talk at the Penn State Action club meeting. HTML slides.\nJayaraman, S., Gilmore, R.O., & Raudies, F. (2016, May). Changes in early optic flow experiences across development and culture. Talk at the International Congress on Infant Studies (ICIS) in New Orleans, LA. HTML slides.\nGilmore, R.O. (2016, September). Open science practices have made my work better. Talk at the Penn State Psychology Cognitive Area brown bag. HTML slides.\nAdamiak, W., Thomas, A.L., Patel, S.M., & Gilmore. R.O. (2015, May). Adult observers’ sensitivity to optic flow varies by pattern and speed. Poster presented at the Vision Sciences Society meeting, St. Pete’s Beach, FL. doi:10.1167/15.12.1008. PDF. Materials on Databrary.\nRaudies, F. & Gilmore, R.O. (2014, May). An analysis of optic flow experienced by infants during natural activities. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. Journal of Vision, 14(10). 226. doi:10.1167/14.10.226. PDF\nThomas, A.L., Fesi, J.D. & Gilmore, R.O. (2014, May). Temporal and speed tuning in brain responses to local and global motion patterns. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. Journal of Vision, 14(10). 482. doi:10.1167/14.10.482.\nFesi, J.D., Thomas, A.L., & Gilmore, R.O. (2012, October). Distinct space-time sampling thresholds of VEP responses to optic flow. Poster presented at the Society for Neuroscience meeting, New Orleans, LA. PDF\nGilmore, R.O., Raudies, F., Kretch, K.S., Franchak, J.M., & Adolph, K.E. (2012, June). Do you see what I see? Comparing optic flow experienced by infants and their mothers. Poster presented at the International Conference on Infant Studies, Minneapolis, MN. PDF.\nFesi, J.D., Stiffler, J.R., & Gilmore, R.O. (2012, May). Speed tuning of cortical responses to 2D figures defined by motion contrast is non-uniform across contrast types. Poster presented at the Vision Sciences Society meeting, Naples, FL.\nThomas, A.L., Mancino, A.C., Elnathan, H.C., Fesi, J.D., Hwang, K.R., & Gilmore, R.O. (2012, May). Children’s cortical responses to optic flow patterns show differential tuning by pattern type, speed, scalp location, and age group. Poster presented at the Vision Sciences Society meeting, Naples, FL. PDF.\nGilmore, R.O., Raudies, F., Kretch, K.S., Franchak, J.M., & Adolph, K.E. (2012, May). Patterns of optic flow experienced by infants and their mothers during locomotion. Poster presented at the Vision Sciences Society meeting, Naples, FL. PDF.\nRaudies, F., Kretch, K.S., Franchak, J.M., Mingolla, E., Gilmore, R.O., & Adolph, K.E. (2012, May). Where do mothers point their head when they walk and where do babies point their head when they are carried? Poster presented at the Vision Sciences Society meeting, Naples, FL. PDF.\nMaterials\n\nhttp://databrary.org/volume/73\nhttp://dx.doi.org/10.17910/B7988V\n\nRole\n\nPrincipal Investigator\n\nCollaborators\n\nFlorian Raudies, Hewlett-Packard Research\nSwapnaa Jayaraman, Indiana University\nAmanda Thomas, Swarthmore College\nJeremy Fesi, U.S. Marine Research\n\nSupport\nThis project was supported by the National Science Foundation under grant BCS-1147440.\n\n\n\nDown Syndrome (DS) is the most common known genetic origin of intellectual disability and has an estimated incidence of 1 in every 1000 live births. Such children face unique challenges as they enter into the school years, because the speech that was previously adequate for communication with familiar partners in supportive settings is often not sufficient for academic communication with unfamiliar partners. Indeed, 95% of parents surveyed reported that their children with DS had difficulty being understood by persons outside their immediate social circle (Kumin, 1994). This has significant implications for academic, social, and vocational success; children with limited language skills are at risk of falling behind nondisabled peers academically and experiencing social isolation. Secondary issues often arise when children experience frustration in communication, commonly in the form of challenging behaviors. All aspects of development are further compromised when these behaviors involve aggression toward others, have significant health implications when they are self-injurious, and exacerbate service costs when they necessitate extensive behavior management plans. Children with DS are in desperate need of communication interventions that provide them with the tools to succeed throughout the school years. One form of intervention is called aided augmentative and alternative communication (AAC). In typical clinical applications, aided AAC systems employ picture books, tablet-style computers that present the user with graphic symbols, and sometimes text or synthesized voice output. Because AAC relies on vision rather than sound/speech for access to the communication messages, it is critical to map out how children with DS examine and extract information from visual AAC displays. Otherwise there is the risk of implementing systems that are poorly matched to children’s skills and needs, a practice that in turn results in limited use or abandonment of the system. Few current AAC designs consider the fit between the system and the visual processing skills of users, and most are uninformed by empirical knowledge about human visual information processing. Moreover, little is known about visual processing in persons with significant communication limitations associated with DS. This research aims to improve the design of AAC displays through characterization of visual attention patterns to different AAC displays and their effects on functional use. Eye tracking - rarely used in DS - will reveal attention patterns/processes that typically go unrecorded in behavioral research. Our three-phase program will begin with eye tracking studies of visual attention under largely non-social laboratory conditions. In the next phase, we will introduce social interactions and record gaze path using mobile eye tracking technology. In the final phase, we will translate the knowledge gained in the laboratory studies to optimize functional communication in individuals with DS in performing tasks that represent typical daily life activities.\nRole\n\nCo-Investigator\n\nCollaborators\n\nKrista Wilkinson, Penn State, Principal Investigator\n\nMaterials\nGilmore, R.O. (2017). Wilkinson-lab. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/wilkinson-lab.\nGilmore, R.O. (2017). Eye-tracking-DS. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/eye-tracking-DS.\nSupport\nThe project is supported by NICHD under R01HD083381-02.\nPublications\nWilkinson, K.M., Gilmore, R.O., & Qian, Y. (submitted). Judicious arrangement of symbols on a simulated AAC display optimizes visual attention by individuals with and without Down syndrome. Journal of Speech, Language, and Hearing Research.\n\n\n\n\nA 5-year-old overhears her parents arguing loudly in the next room. She may not understand why they are arguing, but she realizes something is wrong because she perceives anger in their voices. Exposure to interpersonal conflict is consistently associated with less skillful emotion regulation in children although the mechanisms remain to be explained. Because inter-personal conflict is a heterogeneous phenomenon, investigation of the specific features of conflict that contribute to developmental pathways to emotional dysfunction and symptoms requires a process-oriented approach. In this project, we focus on brain responses to angry prosody in natural speech. We are studying young children’s neural processing of angry prosody, spoken by mothers and strangers, as a first step toward a future longitudinal study investigating how the neurocognitive processing of angry prosody mediates relations between conflict exposure in children and the development of anxiety- and anger-related symptoms.\nPublications\nLiu, P., Cole, P.M., Gilmore, R.O., Pérez-Edgar, K.E., Vigeant, M.C., Moriarty, P., Scherf, K.S. (in press). Young children’s neural processing of their mother’s voice: An fMRI study. Neuropsychologia. doi: 10.1016/j.neuropsychologia.2018.12.003.\nMoriarty, P. M., Vigeant, M. C., Liu, P., Gilmore, R., Wolf, R., & Cole, P. M. (2016). Low frequency analysis of acoustical parameters of emotional speech for use with functional magnetic resonance imaging. The Journal of the Acoustical Society of America, 140(4), 3237–3238. Acoustical Society of America. Retrieved from https://doi.org/10.1121/1.4970240\nMaggi, M., Cole, P., Elbich, D., Gilmore, R.O., Pérez–Edgar, K., Scherf, K.S. (in prep). Hearing emotions: School-aged children’s neural processing of the human voice and affective prosody.\nPresentations\nStoop, T.B., Moriarty, P.M., Wolf, R., Gilmore, R.O., Perez-Edgar, K., Scherf, S, Vigeant, M.C., & Cole, P.M. (in press). I know that voice! Mothers’ voices influence children’s perceptions of emotional intensity. Journal of Experimental Child Psychology.\nLiu, P., Cole, P.M., Gilmore, R.O., Pérez-Edgar, K.E., Vigeant, M.C., Moriarty, P., Scherf, K.S. (2019). Young children’s neural processing of their mother’s voice: An fMRI study. Neuropsychologia, 122, 11-19. doi: 10.1016/j.neuropsychologia.2018.12.003.\nMoriarty, P., Vigeant, M., Liu, P. Gilmore, R.O, & Cole, P.M. (submitted) Comparing theory, consensus, and perception to the acoustics of emotional speech.\nMoriarty, P.M., Vigeant, M., Wolf, R., Gilmore, R., & Cole, P. (2018). Creation and characterization of an emotional speech database. The Journal of the Acoustical Society of America, 143(3), 1869–1869. ASA. Retrieved from https://asa.scitation.org/doi/abs/10.1121/1.5036133\nRole\n\nCo-investigator\n\nCollaborators\n\nPamela Cole, Penn State (PI)\nKoraly Perez-Edgar, Penn State\nSuzy Scherf, Penn State\nMichelle Vigeant, Penn State\nPan Liu\nMirella Maggi\nPeter Moriarty, Penn State\nTawni O’Dell, Penn State\n\nMaterials\n\nPEEP II repo on GitHub.\nPEEP I repo on GitHub.\nPEEP I stimuli on Databrary\n\nSupport\nThis project has received support from the Penn State Social Sciences Research Institute and the National Institute of Mental Health under R21-MH-104547.\n\n\n\nDown Syndrome (DS) is the most common known genetic origin of intellectual disability and has an estimated incidence of 1 in every 1000 live births. Such children face unique challenges as they enter into the school years, because the speech that was previously adequate for communication with familiar partners in supportive settings is often not sufficient for academic communication with unfamiliar partners. Indeed, 95% of parents surveyed reported that their children with DS had difficulty being understood by persons outside their immediate social circle (Kumin, 1994). This has significant implications for academic, social, and vocational success; children with limited language skills are at risk of falling behind nondisabled peers academically and experiencing social isolation. Secondary issues often arise when children experience frustration in communication, commonly in the form of challenging behaviors. All aspects of development are further compromised when these behaviors involve aggression toward others, have significant health implications when they are self-injurious, and exacerbate service costs when they necessitate extensive behavior management plans. Children with DS are in desperate need of communication interventions that provide them with the tools to succeed throughout the school years. One form of intervention is called aided augmentative and alternative communication (AAC). In typical clinical applications, aided AAC systems employ picture books, tablet-style computers that present the user with graphic symbols, and sometimes text or synthesized voice output. Because AAC relies on vision rather than sound/speech for access to the communication messages, it is critical to map out how children with DS examine and extract information from visual AAC displays. Otherwise there is the risk of implementing systems that are poorly matched to children’s skills and needs, a practice that in turn results in limited use or abandonment of the system. Few current AAC designs consider the fit between the system and the visual processing skills of users, and most are uninformed by empirical knowledge about human visual information processing. Moreover, little is known about visual processing in persons with significant communication limitations associated with DS. This research aims to improve the design of AAC displays through characterization of visual attention patterns to different AAC displays and their effects on functional use. Eye tracking - rarely used in DS - will reveal attention patterns/processes that typically go unrecorded in behavioral research. Our three-phase program will begin with eye tracking studies of visual attention under largely non-social laboratory conditions. In the next phase, we will introduce social interactions and record gaze path using mobile eye tracking technology. In the final phase, we will translate the knowledge gained in the laboratory studies to optimize functional communication in individuals with DS in performing tasks that represent typical daily life activities.\nRole\n\nCo-Investigator\n\nCollaborators\n\nKrista Wilkinson, Penn State, Principal Investigator\n\nMaterials\nGilmore, R.O. (2017). Wilkinson-lab. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/wilkinson-lab.\nGilmore, R.O. (2017). Eye-tracking-DS. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/eye-tracking-DS.\nSupport\nThe project is supported by NICHD under R01HD083381-02.\n\n\n\n \nThe ability to sense regular or near-regular patterns serves critical biological needs and is equally important for computer vision and machine intelligence. Despite wide variation in the types of regularity present in natural images, research on human and computer processing of pattern regularity has focused primarily on detecting bilateral reflection symmetry, using largely atheoretical approaches. The goals of this interdisciplinary research are to i) use principles of group theory to develop a conceptual framework for understanding regularity perception and brain activation in humans, and ii) to design general computer-based symmetry detection algorithms that can operate at a level of practical usability.\nPublication\nKohler, P.J., Vedak, S., Y& Gilmore, R.O. (in prep). Perceptual similarities among wallpaper group exemplars. GitHub repo: https://github.com/gilmore-lab/symmetry-sorting.\nPresentations\nVedak, S.C., Gilmore, R.O., Kohler, P.J., Liu, Y., & Norcia, A.M. (2015, May). The salience of low-order visual features in highly self-similar wallpaper groups. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. PDF. Materials on Databrary.\nThomas, A.L., Gilmore, R.O., Norcia, A.M., Liu, Y., Fesi, J.D., Hwang, K.D., Stitt, J., & Liu, J. (2012, October). Visual patterns with rotational symmetry activate distinct cortical regions. Poster presented at the Society for Neuroscience meeting, New Orleans, LA.\nRole\n\nCo-Investigator\n\nCollaborators\n\nYanxi Liu, Penn State Computer Science & Engineering\nAnthony Norcia, Stanford University, Department of Psychology\nPeter Kohler, York University\n\nSupport\nThis project was supported by the National Science Foundation under grant IIS-1248076."
  },
  {
    "objectID": "research.html#open-science",
    "href": "research.html#open-science",
    "title": "research",
    "section": "",
    "text": "The social, behavioral, and neural sciences face more difficult scientific challenges than any other field has faced before. Open, transparent, and reproducible scientific practices are essential for accelerating discovery in these fields. My colleagues and I are developing policies for the ethical and secure sharing of personal data and technologies to allow the analysis and sharing of these data for scientific and educational purposes.\nPublications\nSoska, K.C., Xu, M., Gonzalez, S.L., Herzberg, O., Tamis-LeMonda, C.S., Gilmore, R.O., & Adolph, K.E. (2021). (Hyper)active data curation: A video case study from behavioral science. Journal of eScience Librarianship, 10(3), e1208. https://doi.org/10.7191/jeslib.2021.1208.\nGilmore, R.O., & Qian, Y. (2021). An open developmental science will be more rigorous, robust, and impactful. Infant and Child Development. https://doi.org/10.1002/icd.2254.\nGilmore, R.O., Xu, M., & Adolph, K.E. (2021). Data sharing. In Panecker, S. & Stanley, B. (Eds.), Handbook of Research Ethics in Psychological Science, APA Press, Washington, DC. PDF.\nGilmore, R.O., Cole, P.M., van Aken, M.A.G., Verma S., & Worthman, C.M. (2020). Advancing scientific integrity, transparency, and openness in child development research: Challenges and possible solutions. Child Development Perspectives, 14(1), 9-14. http://dx.doi.org/10.1111/cdep.12360\nOssmy O., Gilmore R.O., Adolph K.E. (2020) AutoViDev: A Computer-Vision Framework to Enhance and Accelerate Research in Human Development. In: Arai K., Kapoor S. (eds) Advances in Computer Vision. CVC 2019. Advances in Intelligent Systems and Computing, vol 944. Springer, Cham. doi: 10.1007/978-3-030-17798-0_14\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2018). Practical solutions for sharing data and materials From psychological research. Advances in Methods and Practices in Psychological Science, SAGE Publications Inc. Retrieved from https://doi.org/10.1177/2515245917746500. OSF preprint.\nGilmore, R.O., Diaz, M.T., Wyble, B.A., & Yarkoni, T. (2017). Progress toward openness, transparency, and reproducibility in cognitive neuroscience. Annals of the New York Academy of Sciences, 1396, 5–18. doi: 10.1111/nyas.13325.\nGilmore, R.O. (2016). From big data to deep insight in developmental science. Wiley Interdisciplinary Reviews Cognitive Science. DOI: 10.1002/wcs.1379.\nPresentations\nGilmore, R.O., Wham, B., & Zinoble, R. (2021, October). Getting ahead of the curve: Responding to emerging data management plan requirements. Presentation as part of the Open Data & Developmental Science (ODDS) Initiative. slides.\nGilmore, R.O. (2021, April). Invited panel presentation to “Changing the Culture of Data Management and Sharing: A Workshop”, National Academies of Science, Engineering, and Medicine.\nGilmore, R.O. (2021, January). “The Human Behaviorome Project”, Invited presentation to the Networking and Information Technology Research and Development (NITRD) workshop on the Future of Federally Supported Data Repositories.\nGilmore, R.O. (2020, September). Invited presentation at FLUX Preconference Workshop on Infant Neuroimaging.\nGilmore, R.O. (2020, May 23). Invited symposium presentation on Open Science for Different Methodological Approaches in Psychology, 2020 meeting of the Association for Psychological Science, Chicago, IL. Cancelled.\nGilmore, R.O. (2020, April 15). The open science revolution: A report from the front lines. Talk given in the Penn State Data Studies Group. slides.\nGilmore, R.O. (2020, February 21). Research computing in child development research. Invited talk to the Penn State Child Study Center. slides.\nGilmore, R.O. (2019, June 3). Making cognitive science even better. Talk given at the James S. McDonnell Foundation retreat. slides.\nGilmore, R.O. (2019, March 28). The whole elephant. Talk given at the Penn State Center for Neural Engineering (CNE) colloquium series. slides.\nGilmore, R.O., Gennetian, L., Kalish, C., Tamis-LeMonda, C.T., & Worthman, C. (2019, March). What SRCD is doing about open science: A conversation hour. Presentation at the 2019 Society for Research in Child Development (SRCD) meeting, Baltimore, MD. slides.\nGilmore, R.O. (2019, January). An open science of human health & behavior. Invited talk given to the College of Health & Human Development. HTML slides.\nGilmore, R.O. (2018, October). The Open Data and Developmental Science (ODDS) Initiative. Invited talk at the Penn State Child Study Center (CSC). HTML slides.\nGilmore, R.O. (2018, October). The promise of open developmental science. Invited talk at the SRCD Conference on the Use of Secondary and Open Source Data in Developmental Science. Phoenix, AZ. HTML slides\nGilmore, R.O. (2018, September). Big data behavioral science: From micro- to macro-scale. Annual Conference of the Federal Statistical Research Data Centers. University Park, PA. HTML slides\nGilmore, R.O. (2018, May). Open, says me: Practical solutions for sharing data and materials. Invited talk at the Association for Psychological Science 2018 meeting. San Francisco, CA. HTML slides\nGilmore, R.O. (2017, September 29). Data sharing, research ethics, & scientific reproducibility. Talk at the Scholarship and Research Integrity (SARI) workshop series, Penn State. HTML slides.\nGilmore, R.O. (2017, September 7). Reproducibility in computationally intensive behavioral research. Talk at the ACI-ICS seminar series, Penn State. HTML slides.\nSoftware\ndatabraryapi, an R package for Databrary. https://github.com/PLAY-behaviorome/databraryapi.\ndatabrarypy, a Python package for Databrary. https://github.com/PLAY-behaviorome/databrarypy.\nRoles\n\nChaired Society for Research in Child Development (SRCD) Task Force on Scientific Integrity and Openness (2018-2019) that drafted a Policy on Scientific Integrity, Transparency, and Openness and author guidelines.\nLead the Open Data & Developmental Science (ODDS) initiative for the Penn State Child Study Center.\nCo-lead R Bootcamp workshop for Penn State graduate students, postdocs, and faculty. 2019 course site, 2018 course site.\n\nCollaborators\n\nKaren Adolph, New York University, Co-Principal Investigator and Project Director.\nOri Ossmy, New York University\nJeff Spies, 221b.io\n\n\nThe Databrary Project aims to increase scientific transparency and accelerate discovery in developmental science by building infrastructure for researchers to share video data and related meta-data. The project has five specific aims:\n\nCreate a web-based data library for sharing and preserving video data and associated meta-data.\nCreate participant and contributor/user standards that enable open sharing of video data while limiting access to authorized users to ensure participant confidentiality.\nExpand the free, open source video coding software, Datavyu to enable coding, exploring, and analyzing video data.\nBuild a data management system to support data sharing within labs, among collaborators, and in the Databrary repository.\nTransform the culture of developmental science by building a community of researchers committed to open video data sharing.\n\nDatabrary is an open-source software project. Penn State is one of the major “nodes”, with a large number of authorized users.\nPublications\nGilmore, R.O., Xu, M., & Adolph, K.E. (2021). Data sharing. In Panecker, S. & Stanley, B. (Eds.), Handbook of Research Ethics in Psychological Science, APA Press, Washington, DC.\nGilmore, R. O. & Adolph, K. E. (2019). Open sharing of research video: Breaking down the boundaries of the research team. In , K. L. Hall, A. L. Vogel, & R. T. Croyle (Eds.), Strategies for team science success: Handbook of evidence-based principles for cross-disciplinary science and practical lessons learned from health researchers. Cham: Springer, pp. 575-583.\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2018). Practical solutions for sharing data and materials From psychological research. Advances in Methods and Practices in Psychological Science, SAGE Publications Inc. Retrieved from https://doi.org/10.1177/2515245917746500. OSF preprint.\nAdolph, K.E., Gilmore, R.O., & Kennedy, J.L. (2017, October). Video data and documentation will improve psychological science. Psychological Science Agenda. http://www.apa.org/science/about/psa/2017/10/video-data.aspx\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2017, September 7). Practical solutions for the ethical sharing of identifiable research data. Retrieved from http://psyarxiv.com/kew8u.\nGilmore, R.O. & Adolph, K.E. (2017). Video can make behavioural science more reproducible. Nature Human Behaviour. doi:10.1038/s41562-017-0128.\nGilmore, R.O., & Adolph, K.E. (2017, February 6). Video can make science more open, transparent, robust, and reproducible. Retrieved from http://osf.io/3kvp7.\nGilmore, R.O., Adolph, K.E., Millman, D.S. (2016). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. PDF of paper.\nGilmore, R.O., Adolph, K.E., Millman, D.S., & Gordon, A. (2016). Transforming education research through open video data sharing. Advances in Engineering Education, 5(2). HTML.\nGordon, A., Millman, D.S., Steiger, L., Adolph, K.E., & Gilmore, R.O. (2015). Researcher-library collaborations: Data repositories as a service for researchers. Journal of Librarianship and Scholarly Communication. doi:10.7710/2162-3309.1238.\nAdolph, K.E., Gilmore, R.O., Freeman, C., Sanderson, P., & Millman, D. (2012). Toward Open Behavioral Science, Psychological Inquiry: An International Journal for the Advancement of Psychological Theory, 23(3), 244-247. doi:10.1080/1047840X.2012.705133.\nPresentations\nGilmore, R.O. (2019, June 6). Video as data and documentation. Workshop at a Symposium Honoring Brian MacWhinney, Carnegie Mellon University, Pittsburgh, PA. slides.\nGilmore, R.O. (2018, October). Sharing video data. Data blitz talk at the SRCD Conference on the Use of Secondary and Open Source Data in Developmental Science. Phoenix, AZ. HTML slides\nGilmore, R.O., Adolph, K.E., & Seisler, A.S. (2018, October). Sharing nicely with others: Moving developmental scientists toward open data sharing. Poster presented at the SRCD Conference on the Use of Secondary and Open Source Data in Developmental Science. Phoenix, AZ. PDF.\nGilmore, R.O. (2018, April 25). Video as data and documentation. Talk in the Department of Communication Arts & Sciences, Penn State. HTML slides\nGilmore, R.O. (2018, February 14). The future of quantitative developmental science. Talk given at the Quantitative Developmental Methodology brown bag series. HTML slides.\nGilmore, R.O. (2018, January 31). Introducing Databrary. Talk given at the Penn State Software in the Humanities & Social Sciences workshop. HTML slides.\nGilmore, R.O. (2018, January 26). The Video DatAbservatory: A platform for behavioral discovery. Talk at the Pathways to Competence initiative meeting of the Penn State Child Study Center. HTML slides.\nGilmore, R.O. (2017, August 1). Video can improve the reproducibility of psychological science. Lightning talk at the Society for Improving Psychological Science meeting, Charlottesville, VA. HTML slides\nGilmore, R.O. (2017, July 31). Beyond physics envy: Toward a databservatory for human behavior. Lightning talk at the Society for Improving Psychological Science meeting, Charlottesville, VA. HTML slides.\nGilmore, R.O. & Nilsonne, G. (2017, July 30). IRBs and the ethical sharing of research data. Talk given at the Society for Improving Psychological Science meeting, Charlottesville, VA. HTML slides. OSF project.\nGilmore, R.O. (2017, July 26). Yes, we can. Invited panelist at the AERA Workshop on Data Sharing and Research Transparency at the Article Publishing Stage. HTML slides.\nGilmore, R.O. (2017, July 10). The reproducibility crisis in psychology & neuroscience. Talk given at the Penn State Data Reproducibility Bootcamp. HTML slides.\nAdolph, K.E., Binion, G. Gilmore, R.O., Oakes, L., & Vazire, S. (2017, April 6). Openness, replication, & data reuse in developmental science – unique challenges, existing resources, & what is still needed. Invited roundtable at the Society for Research in Child Development meeting, Austin, TX.\nGilmore, R.O. (2017, February 22). A Databservatory for human behavior. Talk given at the Cognitive Area Brown Bag. HTML slides.\nGilmore, R.O. (2017, January 31). An -ome of our own: Toward a more reproducible, robust, and insightful science of human behavior. Talk given to the Social Data Analytics (SoDA) 501 students. Penn State University. HTML slides\nGilmore, R.O. (2016, October). The future of big data in developmental science. Talk given at a meeting of the Penn State Child Study Center (CSC) faculty. HTML slides.\nGilmore, R.O. (2016, September). Donald Rumsfeld and the promise of a ‘big data’ science of human behavior. Talk given at a meeting of the Stochastic Modeling and Computational Statistics (SMACS) group, Department of Statistics. HTML slides.\nGilmore, R.O., Adolph, K.E., & Millman, D.S. (2016, August). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. HTML slides. PDF of paper.\nGilmore, R.O., Adolph, K.E., & Millman, D. (2016, May). Video doesn’t lie: Reproducible workflows with Databrary. Talk given at the NYU Data Science Center Symposium on Reproducibility. HTML slides\nGilmore, R.O., Adolph, K.E., Millman, D.S., Steiger, L., & Simon, D.A. (2015, May). Sharing displays and data from vision science research with Databrary. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. PDF.\nSimon, D.A., Gordon, A.S., Steiger, L., & Gilmore, R.O. (2015, June). Databrary: Enabling sharing and reuse of research video. Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries, Knoxville, TN. doi:10.1145/2756406.2756951\nRole\n\nServe as co-founder and co-director.\n\nCollaborators\n\nKaren Adolph, New York University, Co-Principal Investigator and Project Director.\nDavid Millman, New York University, Co-Investigator.\nJeff Spies, Consulting Chief Technology Officer, Databrary\n\nSupport\nThis project is supported by the U.S. National Science Foundation (NSF) Grant No. BCS-1238599, the Eunice Kennedy Shriver National Institute of Child Health and Human Development under Cooperative Agreement 1-U01-HD-076595-01, the Society for Research in Child Development, the LEGO Foundation, the Alfred P. Sloan Foundation, and the James S. McDonnell Foundation.\n\n\nThe Play & Learning Across a Year (PLAY) project serves as a model system for doing development science from a “big” data approach. Natural free play represents the foundation of infant learning, but we know little about how infants play, how play unfolds in real time and across development, and how individual and group differences promote infant learning and development through play. To answer these questions, the PLAY project will collect, code, and share 900 hours of video collected in the homes of children at 12, 18, and 24 months of age drawn from 30 sites across North America.\nThe aim of the project is to develop a new approach to developmental science that enables (1) “big” data science for researchers who would not otherwise have access; (2) a communal, low-cost means of collecting and coding data that retains the autonomy of individual labs; and (3) a plan for leveraging diverse expertise to address a common goal.\nPublications\nSoska, K.C., Xu, M., Gonzalez, S.L., Herzberg, O., Tamis-LeMonda, C.S., Gilmore, R.O., & Adolph, K.E. (2021). (Hyper)active data curation: A video case study from behavioral science. Journal of eScience Librarianship, 10(3), e1208. https://doi.org/10.7191/jeslib.2021.1208.\nPresentations\nGilmore, R.O., Jayaraman, S., Hassan, S., & Lingeman, J. (2020, July). Tools for reproducible developmental science. Poster to be presented at the 2020 International Congress on Infant Studies, Glasgow, Scotland.\nAdolph, K.E., Tamis-LeMonda, C., & Gilmore, R.O. (2016, December 16). Video-based communal data collection & coding: Advancing the science of infant learning & development. A workshop held at the Eunice Kennedy Shriver National Institute of Child Health and Human Development. Video Cast. Materials & data.\nMaterials\nGilmore, R.O. (2017). PLAY-behaviorome. Github code repository. Retrieved December 19, 2017 from https://github.com/PLAY-behaviorome/.\nAdolph, K., Tamis-LeMonda, C. & Gilmore, R.O. (2017). PLAY Pilot Data Collections. Databrary. Retrieved December 19, 2017 from https://nyu.databrary.org/volume/444.\nAdolph, K., Tamis-LeMonda, C. & Gilmore, R.O. (2016). PLAY Project: Materials. Databrary. Retrieved December 19, 2017 from https://nyu.databrary.org/volume/254.\nAdolph, K., Tamis-LeMonda, C. & Gilmore, R.O. (2016). PLAY Project: Webinar discussions on protocol and coding. Databrary. Retrieved December 19, 2017 from https://nyu.databrary.org/volume/232.\nRole\n\nServe as Co-PI and head of data science.\n\nCollaborators\n\nKaren Adolph, New York University, Co-Principal Investigator.\nCatherine Tamis-LeMonda, New York University, Co-Principal Investigator.\nKasey Soska, New York University, Scientific Director.\n\nSupport\nPLAY is supported by grants from the Office of the Director, National Institutes of Health, (OD), Eunice Kennedy Shriver National Institute for Child Health and Human Development (NICHD), the National Institute of Mental Health (NIMH), and the National Institute on Drug Abuse (NIDA) under R01HD094830-01, the LEGO Foundation, and the Alfred P. Sloan Foundation."
  },
  {
    "objectID": "research.html#sex-differences-in-visual-perception",
    "href": "research.html#sex-differences-in-visual-perception",
    "title": "research",
    "section": "",
    "text": "Previous research has shown that males and females differ on a number of psychological dimensions, including some basic aspects of visual processing. We are exploring the extent to which low-level visual dimensions of visual processing correlate with one another and with higher order characteristics like spatial cognition and hobby choices.\nRole\n\nCo-Investigator\n\nMaterials\n\nGitHub project\n\nCollaborators\n\nSheri Berenbaum, Penn State\nYiming Qian, Penn State\n\nPublications\nBerenbaum, S.A., Qian, Y., & Gilmore, R.O. (in prep). Vision contributes to sex differences in spatial cognition and activity interests.\nPresentations"
  },
  {
    "objectID": "research.html#behavioral-analysis-through-video-behav.ai",
    "href": "research.html#behavioral-analysis-through-video-behav.ai",
    "title": "research",
    "section": "",
    "text": "AI and computer vision tools are increasingly useful in basic and applied behavioral science. This project aims to provide a set of tools based on open source algorithms and models that empowers non-specialists to exploit advances in these areas.\nMaterials\n\nGitHub project\n\nRole\n\nPrincipal Investigator\n\nCollaborators\n\nDan Albohn, Penn State Department of Psychology\nKory Blose, Penn State Applied Research Lab\nStephen Fast, Penn State Applied Research Lab\nOri Ossmy, New York University\nDrew Polasky, Penn State Institute for Cyberscience"
  },
  {
    "objectID": "research.html#developmental-dynamics-of-optic-flow-processing",
    "href": "research.html#developmental-dynamics-of-optic-flow-processing",
    "title": "research",
    "section": "",
    "text": "Visual motion provides humans and animals with information about their own movement through 3D space and about the structure of the environment – the objects, surfaces, and other animals that it may contain. How the human brain processes complex motion information poses an as-yet unanswered question. This project focuses on characterizing how sensitivity to visual motion emerges in the developing human brain: how brain (EEG) responses to patterns of ego- and object motion emerge, how they develop from infancy through childhood into adulthood, how specific changes in cortical circuitry might account for the observed patterns, and how behavioral sensitivity to motion corresponds to neural activation. The studies compare brain responses and behavioral discrimination patterns in infants, children, and adults to the same types of ego- and object motion. The studies also involve an effort to measure or simulate the statistics of optic flow experienced by infant, child, and adult observers in complex, natural environments using computer vision methods.\nPublications\nQian, Y., Seisler, A.R., & Gilmore, R.O. (in press). Children’s sensitivity to optic flow-like visual motion differs from adults. Developmental Psychology. GitHub repository at https://github.com/gilmore-lab/sex-differences-in-motion-perception\nGilmore, R.O., Thomas, A.L., & Fesi, J.D (2016). Children’s brain responses to optic flow vary by pattern type and motion speed. PLoS ONE. doi: 10.1371/journal.pone.0157911. Materials on Databrary at http://doi.org/10.17910/B7QG6W.\nGilmore, R.O., Raudies, F., & Jayaraman, S. (2015). What Accounts for Developmental Shifts in Optic Flow Sensitivity? Proceedings of the IEEE International Conference on Development and Learning and Epigenetic Robotics. doi:10.1109/DEVLRN.2015.7345450. Materials on Databrary at doi:10.17910/B7988V.\nFesi, J.F., Thomas, A.L., & Gilmore, R.O. (2014). Cortical responses to optic flow and motion contrast across patterns and speeds. Vision Research, 100, 56–71. doi:10.1016/j.visres.2014.04.004. Materials on Databrary.\nRaudies, F. & Gilmore, R.O. (2014). Visual motion priors differ for infants and mothers. Neural Computation, 26(11), 2652-2668. doi:10.1162/NECO_a_00645.\nRaudies, F., Gilmore, R.O., Kretch, K.S., Franchak, J.M, & Adolph, K.E. (2012). Understanding the development of motion processing by characterizing optic flow experienced by infants and their mothers. Proceedings of the IEEE International Conference on Development and Learning. doi:10.1109/DevLrn.2012.6400584.\nPresentations\nGilmore, R.O. (2018, February 24). The development of perception for action. Data blitz talk at the Developmental Area graduate recruiting weekend. HTML slides.\nGilmore, R.O., Seisler, A., Shade, M., O’Neill, M. (2017, April). School-age children perceive fast radial optic flow in noise more accurately than slow linear flow. Poster presentation at the Society for Research in Child Development, Austin, TX. PDF. Databrary. GitHub.\nGilmore, R.O. (2017, February). Go with the flow: The development of behavioral sensitivity and brain responses to optic flow. Talk at Temple University. HTML slides. Markdown.\nGilmore, R.O., Fared, D.A., Dexheimer, M.G., & Seisler, A.R. (2016, November). The appearance and disappearance of visual forms defined by differential motion evokes distinctive EEG responses in school-age children. Presentation at the Society for Neuroscience meeting in San Diego, CA. PDF.\nGilmore, R.O. (2016, October). Go with the flow: The development of behavioral sensitivity and brain responses to optic flow. Talk at the Penn State Action club meeting. HTML slides.\nJayaraman, S., Gilmore, R.O., & Raudies, F. (2016, May). Changes in early optic flow experiences across development and culture. Talk at the International Congress on Infant Studies (ICIS) in New Orleans, LA. HTML slides.\nGilmore, R.O. (2016, September). Open science practices have made my work better. Talk at the Penn State Psychology Cognitive Area brown bag. HTML slides.\nAdamiak, W., Thomas, A.L., Patel, S.M., & Gilmore. R.O. (2015, May). Adult observers’ sensitivity to optic flow varies by pattern and speed. Poster presented at the Vision Sciences Society meeting, St. Pete’s Beach, FL. doi:10.1167/15.12.1008. PDF. Materials on Databrary.\nRaudies, F. & Gilmore, R.O. (2014, May). An analysis of optic flow experienced by infants during natural activities. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. Journal of Vision, 14(10). 226. doi:10.1167/14.10.226. PDF\nThomas, A.L., Fesi, J.D. & Gilmore, R.O. (2014, May). Temporal and speed tuning in brain responses to local and global motion patterns. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. Journal of Vision, 14(10). 482. doi:10.1167/14.10.482.\nFesi, J.D., Thomas, A.L., & Gilmore, R.O. (2012, October). Distinct space-time sampling thresholds of VEP responses to optic flow. Poster presented at the Society for Neuroscience meeting, New Orleans, LA. PDF\nGilmore, R.O., Raudies, F., Kretch, K.S., Franchak, J.M., & Adolph, K.E. (2012, June). Do you see what I see? Comparing optic flow experienced by infants and their mothers. Poster presented at the International Conference on Infant Studies, Minneapolis, MN. PDF.\nFesi, J.D., Stiffler, J.R., & Gilmore, R.O. (2012, May). Speed tuning of cortical responses to 2D figures defined by motion contrast is non-uniform across contrast types. Poster presented at the Vision Sciences Society meeting, Naples, FL.\nThomas, A.L., Mancino, A.C., Elnathan, H.C., Fesi, J.D., Hwang, K.R., & Gilmore, R.O. (2012, May). Children’s cortical responses to optic flow patterns show differential tuning by pattern type, speed, scalp location, and age group. Poster presented at the Vision Sciences Society meeting, Naples, FL. PDF.\nGilmore, R.O., Raudies, F., Kretch, K.S., Franchak, J.M., & Adolph, K.E. (2012, May). Patterns of optic flow experienced by infants and their mothers during locomotion. Poster presented at the Vision Sciences Society meeting, Naples, FL. PDF.\nRaudies, F., Kretch, K.S., Franchak, J.M., Mingolla, E., Gilmore, R.O., & Adolph, K.E. (2012, May). Where do mothers point their head when they walk and where do babies point their head when they are carried? Poster presented at the Vision Sciences Society meeting, Naples, FL. PDF.\nMaterials\n\nhttp://databrary.org/volume/73\nhttp://dx.doi.org/10.17910/B7988V\n\nRole\n\nPrincipal Investigator\n\nCollaborators\n\nFlorian Raudies, Hewlett-Packard Research\nSwapnaa Jayaraman, Indiana University\nAmanda Thomas, Swarthmore College\nJeremy Fesi, U.S. Marine Research\n\nSupport\nThis project was supported by the National Science Foundation under grant BCS-1147440."
  },
  {
    "objectID": "research.html#eye-tracking-technologies-to-characterize-and-optimize-visual-attending-in-down-syndrome",
    "href": "research.html#eye-tracking-technologies-to-characterize-and-optimize-visual-attending-in-down-syndrome",
    "title": "research",
    "section": "",
    "text": "Down Syndrome (DS) is the most common known genetic origin of intellectual disability and has an estimated incidence of 1 in every 1000 live births. Such children face unique challenges as they enter into the school years, because the speech that was previously adequate for communication with familiar partners in supportive settings is often not sufficient for academic communication with unfamiliar partners. Indeed, 95% of parents surveyed reported that their children with DS had difficulty being understood by persons outside their immediate social circle (Kumin, 1994). This has significant implications for academic, social, and vocational success; children with limited language skills are at risk of falling behind nondisabled peers academically and experiencing social isolation. Secondary issues often arise when children experience frustration in communication, commonly in the form of challenging behaviors. All aspects of development are further compromised when these behaviors involve aggression toward others, have significant health implications when they are self-injurious, and exacerbate service costs when they necessitate extensive behavior management plans. Children with DS are in desperate need of communication interventions that provide them with the tools to succeed throughout the school years. One form of intervention is called aided augmentative and alternative communication (AAC). In typical clinical applications, aided AAC systems employ picture books, tablet-style computers that present the user with graphic symbols, and sometimes text or synthesized voice output. Because AAC relies on vision rather than sound/speech for access to the communication messages, it is critical to map out how children with DS examine and extract information from visual AAC displays. Otherwise there is the risk of implementing systems that are poorly matched to children’s skills and needs, a practice that in turn results in limited use or abandonment of the system. Few current AAC designs consider the fit between the system and the visual processing skills of users, and most are uninformed by empirical knowledge about human visual information processing. Moreover, little is known about visual processing in persons with significant communication limitations associated with DS. This research aims to improve the design of AAC displays through characterization of visual attention patterns to different AAC displays and their effects on functional use. Eye tracking - rarely used in DS - will reveal attention patterns/processes that typically go unrecorded in behavioral research. Our three-phase program will begin with eye tracking studies of visual attention under largely non-social laboratory conditions. In the next phase, we will introduce social interactions and record gaze path using mobile eye tracking technology. In the final phase, we will translate the knowledge gained in the laboratory studies to optimize functional communication in individuals with DS in performing tasks that represent typical daily life activities.\nRole\n\nCo-Investigator\n\nCollaborators\n\nKrista Wilkinson, Penn State, Principal Investigator\n\nMaterials\nGilmore, R.O. (2017). Wilkinson-lab. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/wilkinson-lab.\nGilmore, R.O. (2017). Eye-tracking-DS. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/eye-tracking-DS.\nSupport\nThe project is supported by NICHD under R01HD083381-02.\nPublications\nWilkinson, K.M., Gilmore, R.O., & Qian, Y. (submitted). Judicious arrangement of symbols on a simulated AAC display optimizes visual attention by individuals with and without Down syndrome. Journal of Speech, Language, and Hearing Research."
  },
  {
    "objectID": "research.html#the-proximal-emotional-environment-project-peep",
    "href": "research.html#the-proximal-emotional-environment-project-peep",
    "title": "research",
    "section": "",
    "text": "A 5-year-old overhears her parents arguing loudly in the next room. She may not understand why they are arguing, but she realizes something is wrong because she perceives anger in their voices. Exposure to interpersonal conflict is consistently associated with less skillful emotion regulation in children although the mechanisms remain to be explained. Because inter-personal conflict is a heterogeneous phenomenon, investigation of the specific features of conflict that contribute to developmental pathways to emotional dysfunction and symptoms requires a process-oriented approach. In this project, we focus on brain responses to angry prosody in natural speech. We are studying young children’s neural processing of angry prosody, spoken by mothers and strangers, as a first step toward a future longitudinal study investigating how the neurocognitive processing of angry prosody mediates relations between conflict exposure in children and the development of anxiety- and anger-related symptoms.\nPublications\nLiu, P., Cole, P.M., Gilmore, R.O., Pérez-Edgar, K.E., Vigeant, M.C., Moriarty, P., Scherf, K.S. (in press). Young children’s neural processing of their mother’s voice: An fMRI study. Neuropsychologia. doi: 10.1016/j.neuropsychologia.2018.12.003.\nMoriarty, P. M., Vigeant, M. C., Liu, P., Gilmore, R., Wolf, R., & Cole, P. M. (2016). Low frequency analysis of acoustical parameters of emotional speech for use with functional magnetic resonance imaging. The Journal of the Acoustical Society of America, 140(4), 3237–3238. Acoustical Society of America. Retrieved from https://doi.org/10.1121/1.4970240\nMaggi, M., Cole, P., Elbich, D., Gilmore, R.O., Pérez–Edgar, K., Scherf, K.S. (in prep). Hearing emotions: School-aged children’s neural processing of the human voice and affective prosody.\nPresentations\nStoop, T.B., Moriarty, P.M., Wolf, R., Gilmore, R.O., Perez-Edgar, K., Scherf, S, Vigeant, M.C., & Cole, P.M. (in press). I know that voice! Mothers’ voices influence children’s perceptions of emotional intensity. Journal of Experimental Child Psychology.\nLiu, P., Cole, P.M., Gilmore, R.O., Pérez-Edgar, K.E., Vigeant, M.C., Moriarty, P., Scherf, K.S. (2019). Young children’s neural processing of their mother’s voice: An fMRI study. Neuropsychologia, 122, 11-19. doi: 10.1016/j.neuropsychologia.2018.12.003.\nMoriarty, P., Vigeant, M., Liu, P. Gilmore, R.O, & Cole, P.M. (submitted) Comparing theory, consensus, and perception to the acoustics of emotional speech.\nMoriarty, P.M., Vigeant, M., Wolf, R., Gilmore, R., & Cole, P. (2018). Creation and characterization of an emotional speech database. The Journal of the Acoustical Society of America, 143(3), 1869–1869. ASA. Retrieved from https://asa.scitation.org/doi/abs/10.1121/1.5036133\nRole\n\nCo-investigator\n\nCollaborators\n\nPamela Cole, Penn State (PI)\nKoraly Perez-Edgar, Penn State\nSuzy Scherf, Penn State\nMichelle Vigeant, Penn State\nPan Liu\nMirella Maggi\nPeter Moriarty, Penn State\nTawni O’Dell, Penn State\n\nMaterials\n\nPEEP II repo on GitHub.\nPEEP I repo on GitHub.\nPEEP I stimuli on Databrary\n\nSupport\nThis project has received support from the Penn State Social Sciences Research Institute and the National Institute of Mental Health under R21-MH-104547."
  },
  {
    "objectID": "research.html#eye-tracking-technologies-to-characterize-and-optimize-visual-attending-in-down-syndrome-1",
    "href": "research.html#eye-tracking-technologies-to-characterize-and-optimize-visual-attending-in-down-syndrome-1",
    "title": "research",
    "section": "",
    "text": "Down Syndrome (DS) is the most common known genetic origin of intellectual disability and has an estimated incidence of 1 in every 1000 live births. Such children face unique challenges as they enter into the school years, because the speech that was previously adequate for communication with familiar partners in supportive settings is often not sufficient for academic communication with unfamiliar partners. Indeed, 95% of parents surveyed reported that their children with DS had difficulty being understood by persons outside their immediate social circle (Kumin, 1994). This has significant implications for academic, social, and vocational success; children with limited language skills are at risk of falling behind nondisabled peers academically and experiencing social isolation. Secondary issues often arise when children experience frustration in communication, commonly in the form of challenging behaviors. All aspects of development are further compromised when these behaviors involve aggression toward others, have significant health implications when they are self-injurious, and exacerbate service costs when they necessitate extensive behavior management plans. Children with DS are in desperate need of communication interventions that provide them with the tools to succeed throughout the school years. One form of intervention is called aided augmentative and alternative communication (AAC). In typical clinical applications, aided AAC systems employ picture books, tablet-style computers that present the user with graphic symbols, and sometimes text or synthesized voice output. Because AAC relies on vision rather than sound/speech for access to the communication messages, it is critical to map out how children with DS examine and extract information from visual AAC displays. Otherwise there is the risk of implementing systems that are poorly matched to children’s skills and needs, a practice that in turn results in limited use or abandonment of the system. Few current AAC designs consider the fit between the system and the visual processing skills of users, and most are uninformed by empirical knowledge about human visual information processing. Moreover, little is known about visual processing in persons with significant communication limitations associated with DS. This research aims to improve the design of AAC displays through characterization of visual attention patterns to different AAC displays and their effects on functional use. Eye tracking - rarely used in DS - will reveal attention patterns/processes that typically go unrecorded in behavioral research. Our three-phase program will begin with eye tracking studies of visual attention under largely non-social laboratory conditions. In the next phase, we will introduce social interactions and record gaze path using mobile eye tracking technology. In the final phase, we will translate the knowledge gained in the laboratory studies to optimize functional communication in individuals with DS in performing tasks that represent typical daily life activities.\nRole\n\nCo-Investigator\n\nCollaborators\n\nKrista Wilkinson, Penn State, Principal Investigator\n\nMaterials\nGilmore, R.O. (2017). Wilkinson-lab. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/wilkinson-lab.\nGilmore, R.O. (2017). Eye-tracking-DS. Code repository on GitHub. Retrieved December 19, 2017 from https://github.com/gilmore-lab/eye-tracking-DS.\nSupport\nThe project is supported by NICHD under R01HD083381-02."
  },
  {
    "objectID": "research.html#computational-symmetry",
    "href": "research.html#computational-symmetry",
    "title": "research",
    "section": "",
    "text": "The ability to sense regular or near-regular patterns serves critical biological needs and is equally important for computer vision and machine intelligence. Despite wide variation in the types of regularity present in natural images, research on human and computer processing of pattern regularity has focused primarily on detecting bilateral reflection symmetry, using largely atheoretical approaches. The goals of this interdisciplinary research are to i) use principles of group theory to develop a conceptual framework for understanding regularity perception and brain activation in humans, and ii) to design general computer-based symmetry detection algorithms that can operate at a level of practical usability.\nPublication\nKohler, P.J., Vedak, S., Y& Gilmore, R.O. (in prep). Perceptual similarities among wallpaper group exemplars. GitHub repo: https://github.com/gilmore-lab/symmetry-sorting.\nPresentations\nVedak, S.C., Gilmore, R.O., Kohler, P.J., Liu, Y., & Norcia, A.M. (2015, May). The salience of low-order visual features in highly self-similar wallpaper groups. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. PDF. Materials on Databrary.\nThomas, A.L., Gilmore, R.O., Norcia, A.M., Liu, Y., Fesi, J.D., Hwang, K.D., Stitt, J., & Liu, J. (2012, October). Visual patterns with rotational symmetry activate distinct cortical regions. Poster presented at the Society for Neuroscience meeting, New Orleans, LA.\nRole\n\nCo-Investigator\n\nCollaborators\n\nYanxi Liu, Penn State Computer Science & Engineering\nAnthony Norcia, Stanford University, Department of Psychology\nPeter Kohler, York University\n\nSupport\nThis project was supported by the National Science Foundation under grant IIS-1248076."
  },
  {
    "objectID": "posts/visual-acuity-new-figs.html",
    "href": "posts/visual-acuity-new-figs.html",
    "title": "Preliminary figures from Legacy: Visual Acuity",
    "section": "",
    "text": "Several RAs have taken the bull by the horns and made significant progress on the research protocol for the Legacy Project: Visual Acuity study.\nIn the meantime, Rick went ahead and made a very preliminary plot of what the eventual study-level data might look like:\n\n\n\nFigure from https://gilmore-lab.github.io/visual-acuity/data.html#fig-teller-acuity-across-age\n\n\nWith a bit of tweaking of some archival data, Rick also wrangled the following plot of some individual-level data.\n\n\n\nFigure from https://gilmore-lab.github.io/visual-acuity/data.html#fig-gilmore-lab-archival"
  },
  {
    "objectID": "posts/lab-mtg-2023-09-12.html",
    "href": "posts/lab-mtg-2023-09-12.html",
    "title": "Lab meeting: 2023-09-12",
    "section": "",
    "text": "PLAY Project Logo\n\n\nMadison Gehringer talked about the Play & Learning Across a Year (PLAY) Project in today’s lab meeting. We had a great discussion about the ethics of sharing identifiable data like video, among other topics."
  },
  {
    "objectID": "posts/lab-mtg-2023-09-19.html",
    "href": "posts/lab-mtg-2023-09-19.html",
    "title": "Lab meeting: 2023-09-19",
    "section": "",
    "text": "Rick and the Legacy Project: Visual Acuity talked about progress on this project, especially the excellent protocol Brianna Beamer drafted from scratch and the comments Julia DiFulvio made on the draft.\nMadison Gehringer, Belle Peterson, and Andrea gave updates about PLAY.\nAndrea and Yinghe Liu talked about progress on the Databrary Guide.\n\n\n\n\n\n\nImportant\n\n\n\nWho wants to be the lab website webmaster?\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe need bios from a number of new folks."
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html",
    "href": "lab-mtgs/notes-murray-2018.html",
    "title": "notes-murray-2018",
    "section": "",
    "text": "Notes and resources to discuss\nMurray, S. O., Schallmo, M.-P., Kolodny, T., Millin, R., Kale, A., Thomas, P., Rammsayer, T. H., et al. (2018). Sex Differences in Visual Motion Processing. Current Biology: CB. Retrieved from http://dx.doi.org/10.1016/j.cub.2018.06.014"
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html#background",
    "href": "lab-mtgs/notes-murray-2018.html#background",
    "title": "notes-murray-2018",
    "section": "",
    "text": "Notes and resources to discuss\nMurray, S. O., Schallmo, M.-P., Kolodny, T., Millin, R., Kale, A., Thomas, P., Rammsayer, T. H., et al. (2018). Sex Differences in Visual Motion Processing. Current Biology: CB. Retrieved from http://dx.doi.org/10.1016/j.cub.2018.06.014"
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html#figure-1",
    "href": "lab-mtgs/notes-murray-2018.html#figure-1",
    "title": "notes-murray-2018",
    "section": "Figure 1",
    "text": "Figure 1"
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html#figure-2",
    "href": "lab-mtgs/notes-murray-2018.html#figure-2",
    "title": "notes-murray-2018",
    "section": "Figure 2",
    "text": "Figure 2"
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html#supplemental-materials",
    "href": "lab-mtgs/notes-murray-2018.html#supplemental-materials",
    "title": "notes-murray-2018",
    "section": "Supplemental Materials",
    "text": "Supplemental Materials\nhttps://www.cell.com/cms/10.1016/j.cub.2018.06.014/attachment/4f09c701-2144-4732-b7e6-92265a65ed7d/mmc1.pdf"
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html#additional-sources-of-data",
    "href": "lab-mtgs/notes-murray-2018.html#additional-sources-of-data",
    "title": "notes-murray-2018",
    "section": "Additional sources of data",
    "text": "Additional sources of data\nMelnick, M. D., Harrison, B. R., Park, S., Bennetto, L., & Tadin, D. (2013). A strong interactive link between sensory discriminations and intelligence. Current biology: CB, 23(11), 1013–1017. Retrieved from http://dx.doi.org/10.1016/j.cub.2013.04.053\nTroche, S. J., Thomas, P., Tadin, D., & Rammsayer, T. H. (2018). On the relationship between spatial suppression, speed of information processing, and psychometric intelligence. Intelligence, 67, 11–18. Retrieved from http://www.sciencedirect.com/science/article/pii/S0160289617302027"
  },
  {
    "objectID": "lab-mtgs/notes-murray-2018.html#what-do-the-stimuli-look-like",
    "href": "lab-mtgs/notes-murray-2018.html#what-do-the-stimuli-look-like",
    "title": "notes-murray-2018",
    "section": "What do the stimuli look like?",
    "text": "What do the stimuli look like?\n\nDocumentation about PsychoPy GratingStim function"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html",
    "href": "lab-mtgs/notes-cohen-2017.html",
    "title": "notes-on-cohen-2017",
    "section": "",
    "text": "Notes for discussing\nCohen, M. X. (2017). Where Does EEG Come From and What Does It Mean? Trends in Neurosciences, 40(4), 208–218. Retrieved from http://dx.doi.org/10.1016/j.tins.2017.02.004"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html#background",
    "href": "lab-mtgs/notes-cohen-2017.html#background",
    "title": "notes-on-cohen-2017",
    "section": "",
    "text": "Notes for discussing\nCohen, M. X. (2017). Where Does EEG Come From and What Does It Mean? Trends in Neurosciences, 40(4), 208–218. Retrieved from http://dx.doi.org/10.1016/j.tins.2017.02.004"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html#figure-1",
    "href": "lab-mtgs/notes-cohen-2017.html#figure-1",
    "title": "notes-on-cohen-2017",
    "section": "Figure 1",
    "text": "Figure 1"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html#figure-2",
    "href": "lab-mtgs/notes-cohen-2017.html#figure-2",
    "title": "notes-on-cohen-2017",
    "section": "Figure 2",
    "text": "Figure 2"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html#issues",
    "href": "lab-mtgs/notes-cohen-2017.html#issues",
    "title": "notes-on-cohen-2017",
    "section": "Issues",
    "text": "Issues\n\nFrom single cell spike (action potential) trains to EEG"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html#terms",
    "href": "lab-mtgs/notes-cohen-2017.html#terms",
    "title": "notes-on-cohen-2017",
    "section": "Terms",
    "text": "Terms\n\nForward model\nInverse model\nLocal field potential\n\\(\\alpha\\), \\(\\beta\\), \\(\\delta\\), \\(\\gamma\\) band oscillations\nwavelet\nFourier transform"
  },
  {
    "objectID": "lab-mtgs/notes-cohen-2017.html#possible-additional-readings",
    "href": "lab-mtgs/notes-cohen-2017.html#possible-additional-readings",
    "title": "notes-on-cohen-2017",
    "section": "Possible additional readings",
    "text": "Possible additional readings\nJackson, A. F., & Bolger, D. J. (2014). The neurophysiological bases of EEG and EEG measurement: A review for the rest of us. Psychophysiology. Wiley Online Library. Retrieved from http://onlinelibrary.wiley.com/doi/10.1111/psyp.12283/full\n\nFigure 1 from Jackson & Bolger, 2014\n\n\n\nFigure 2 from Jackson & Bolger, 2014\n\n\n\nFigure 3 from Jackson & Bolger, 2014\n\n\n\nFigure 4 from Jackwon & Bolger, 2014"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brain and Behavioral Dynamics Lab",
    "section": "",
    "text": "Brain and Behavioral Dynamics Lab in the Psychology Department at Penn State studies the development of perception, action, and memory. Our goal is to understand patterns of brain and behavioral change in infants, children, and young adults. We use behavioral, EEG, MRI, and computational modeling methods in our research. We also advocate for and try to demonstrate open science practices in our work.\nProfessor Rick Gilmore directs the lab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nLab meeting: 2023-10-10\n\n\n\n\n\n\n\nlab meetings\n\n\nVisual Acuity\n\n\nR\n\n\nquarto\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPreliminary figures from Legacy: Visual Acuity\n\n\n\n\n\n\n\nvisual acuity\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLab meeting: 2023-09-19\n\n\n\n\n\n\n\nlab meetings\n\n\nPLAY\n\n\nDatabrary\n\n\nVisual Acuity\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLab meeting: 2023-09-12\n\n\n\n\n\n\n\nlab meetings\n\n\nPLAY\n\n\nDatabrary\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nNew website!\n\n\n\n\n\n\n\nwebsite\n\n\nquarto\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "publications",
    "section": "",
    "text": "Gilmore, R.O. & Lockman, J.J. (Eds.). (2022). New Methods and Approaches for Studying Child Development (Vol. 63). Elsevier Science.\nJohnson, M.H., Munakata, Y., & Gilmore, R.O. (2002). Brain development and cognition: A reader, 2nd Ed. Cambridge: Blackwell."
  },
  {
    "objectID": "publications.html#books",
    "href": "publications.html#books",
    "title": "publications",
    "section": "",
    "text": "Gilmore, R.O. & Lockman, J.J. (Eds.). (2022). New Methods and Approaches for Studying Child Development (Vol. 63). Elsevier Science.\nJohnson, M.H., Munakata, Y., & Gilmore, R.O. (2002). Brain development and cognition: A reader, 2nd Ed. Cambridge: Blackwell."
  },
  {
    "objectID": "publications.html#peer-reviewed-articles",
    "href": "publications.html#peer-reviewed-articles",
    "title": "publications",
    "section": "Peer-reviewed Articles",
    "text": "Peer-reviewed Articles\nSoska, K.C., Xu, M., Gonzalez, S.L., Herzberg, O., Tamis-LeMonda, C.S., Gilmore, R.O., & Adolph, K.E. (2021). (Hyper)active data curation: A video case study from behavioral science. Journal of eScience Librarianship, 10(3), e1208. https://doi.org/10.7191/jeslib.2021.1208.\nGilmore, R.O., & Qian, Y. (2021). An open developmental science will be more rigorous, robust, and impactful. Infant and Child Development. https://doi.org/10.1002/icd.2254.\nQian, Y., Seisler, A. R., & Gilmore, R. O. (2021). Children’s perceptual sensitivity to optic flow-like visual motion differs from adults. Developmental psychology, 57(11), 1810–1821. https://doi.org/10.1037/dev0001227\nLiao, B., Hu, J, & Gilmore, R.O. (2021). Optical flow estimation combining with illumination adjustment and edge refinement in livestock UAV videos. Computers in Electronics and Agriculture, 180, January 2021, 105910. https://doi.org/10.1016/j.compag.2020.105910.\nCuadra, C., Gilmore, R.O., & Latash, M. (2020). Finger force matching and verbal reports: Testing predictions of the Iso-Perceptual Manifold (IPM) concept, Journal of Motor Behavior, 1-13. https://doi.org/10.1080/00222895.2020.1813681.\nStoop, T. B., Moriarty, P. M., Wolf, R., Gilmore, R. O., Perez-Edgar, K., Scherf, K. S., Vigeant, M. C. & Cole, P. M. (2020). I know that voice! Mothers’ voices influence children’s perceptions of emotional intensity. Journal of Experimental Child Psychology, 199(104907), 104907. https://doi.org/10.1016/j.jecp.2020.104907\nGilmore, R.O., Cole, P.M., van Aken, M.A.G., Verma S., & Worthman, C.M. (2020). Advancing scientific integrity, transparency, and openness in child development research: Challenges and possible solutions. Child Development Perspectives, 14(1), 9-14. https://dx.doi.org/10.1111/cdep.12360\nOssmy O., Gilmore R.O., Adolph K.E. (2020) AutoViDev: A Computer-Vision Framework to Enhance and Accelerate Research in Human Development. In: Arai K., Kapoor S. (eds) Advances in Computer Vision. CVC 2019. Advances in Intelligent Systems and Computing, vol 944. Springer, Cham. doi: 10.1007/978-3-030-17798-0_14\nLiu, P., Cole, P.M., Gilmore, R.O., Pérez-Edgar, K.E., Vigeant, M.C., Moriarty, P., Scherf, K.S. (2019). Young children’s neural processing of their mother’s voice: An fMRI study, 11-19. Neuropsychologia. doi: 10.1016/j.neuropsychologia.2018.12.003.\nGilmore, R.O., Kennedy, J.L., & Adolph, K.E. (2018). Practical Solutions for Sharing Data and Materials From Psychological Research. Advances in Methods and Practices in Psychological Science, SAGE Publications Inc. Retrieved from https://doi.org/10.1177/2515245917746500\nGilmore, R.O. & Adolph, K.E. (2017). Video can make behavioural science more reproducible. Nature Human Behaviour. doi:10.1038/s41562-017-0128.\nGilmore, R.O., Diaz, M.T., Wyble, B.A., & Yarkoni, T. (2017). Progress toward openness, transparency, and reproducibility in cognitive neuroscience. Annals of the New York Academy of Sciences, 1396, 5–18. doi: 10.1111/nyas.13325.\nGilmore, R.O., Adolph, K.E., & Millman, D.S. (2016). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. doi: 10.1109/NYSDS.2016.7747817.\nGilmore, R.O., Thomas, A.L., & Fesi, J.D (2016). Children’s brain responses to optic flow vary by pattern type and motion speed. PLoS ONE. doi: 10.1371/journal.pone.0157911. Materials on Databrary at https://doi.org/10.17910/B7QG6W.\nGilmore, R.O., Adolph, K.E., Millman, D.S. & Gordon, A. (2016). Transforming education research through open video data sharing. Advances in Engineering Education, 5(2). HTML.\nGilmore, R.O. (2016). From big data to deep insight in developmental science. Wiley Interdisciplinary Reviews Cognitive Science, 7(2), 112-126. doi: 10.1002/wcs.1379.\nGordon, A., Millman, D.S., Steiger, L., Adolph, K.E., & Gilmore, R.O. (2015). Researcher-library collaborations: Data repositories as a service for researchers. Journal of Librarianship and Scholarly Communication. doi:10.7710/2162-3309.1238.\nGilmore, R.O., Raudies, F., & Jayaraman, S. (2015). What accounts for developmental shifts in optic flow sensitivity? Proceedings of the IEEE International Conference on Development and Learning and Epigenetic Robotics. doi:10.1109/DEVLRN.2015.7345450. Materials on Databrary at doi:10.17910/B7988V.\nEly, A.L., Weinstein, J.M., Price, J.M., Gillon, J.T., Boltz, M.E., Mowery, S.F., Aminlari, A., Gilmore, R.O., & Cheung, A.Y., (2014). Degradation of swept parameter VEP responses by neutral density filters in amblyopic and normal subjects. Investigative Ophthalmology and Visual Science, 55(13), 7248-7255. doi:10.1167/iovs.14-15052.\nRaudies, F. & Gilmore, R.O. (2014). Visual motion priors differ for infants and mothers. Neural Computation, 26(11), 2652-2668. doi:10.1162/NECO_a_00645.\nFesi, J.D., Thomas, A.L., & Gilmore, R.O. (2014). Cortical responses to optic flow and motion contrast across patterns and speeds. Vision Research, 100, 56–71. doi:10.1016/j.visres.2014.04.004. Materials on Databrary.\nBeltz, A.M., Gates, K.M., Engels, A.S., Molenaar, P., Pulido, C., Turrisi, R., Berenbaum, S.A., Gilmore, R.O., & Wilson, S.J. (2013). Changes in alcohol-related brain networks across the first year of college: A prospective pilot study using fMRI effective connectivity mapping. Addictive Behaviors, 38(4), 2052-2059. doi:10.1016/j.addbeh.2012.12.023.\nRaudies, F., Gilmore, R.O., Kretch, K.S., Franchak, J.M, & Adolph, K.E. (2012). Understanding the development of motion processing by characterizing optic flow experienced by infants and their mothers. Proceedings of the IEEE International Conference on Development and Learning. doi:10.1109/DevLrn.2012.6400584.\nAdolph, K.E., Gilmore, R.O., Freeman, C., Sanderson, P., & Millman, D. (2012). Toward open behavioral science, Psychological Inquiry: An International Journal for the Advancement of Psychological Theory, 23(3), 244-247. doi:10.1080/1047840X.2012.705133.\nFesi, J.D., Yannes, M.P., Brinckman, D.D., Norcia, A.M., Ales, J.M., & Gilmore, R.O. (2011). Distinct cortical responses to 2D figures defined by motion contrast. Vision Research, 51(19), 2110-2120. doi:10.1016/j.visres.2011.07.015\nPemberton, C., Bass, A., Moore, G., Murray-Kolb, L., Tan, P., Gilmore, R.O., Buss, K., Cole, P.M, & Teti, L.O. (2011). Let me go: The influence of crawling experience and temperament on the development of anger reactivity and regulation. Infancy, 17(5), 558-577. doi:10.1111/j.1532-7078.2011.00092.x\nWeinstein, J.M., Gilmore, R.O., Trescher, W.V., Shaikh, S.M., Tashima, L.M., Boltz, M.E., McAuliffe, M.B., Cheung, A., Fesi, J.D., & Kunselman, A.R. (2011). Defective motion processing in children with cerebral visual impairment due to periventricular white matter damage. Developmental Medicine & Child Neurology, 53, doi:10.1111/j.1469-8749.2010.03874.x.\nHou, C., Gilmore, R.O., Pettet, M.W., & Norcia, A.M. (2009). Spatio-temporal tuning of coherent motion evoked responses in 4-6 month-old infants and adults. Vision Research, 49(20), 2509-2517. doi:10.1016/j.visres.2009.08.007. Materials on Databrary.\nGilmore, R.O., Hou, C., Pettet, M.W., & Norcia, A.M. (2007). Development of cortical responses to optic flow. Visual Neuroscience, 24, 845-856. doi:10.1017/S0952523807070769.\nKaufman, J., Gilmore, R.O., & Johnson, M.H. (2006). Frames of reference for anticipatory action in 4-month-old infants. Infant Behavior & Development, 29(3), 322-333. doi:10.1016/j.infbeh.2005.01.003\nThomas, H., & Gilmore, R.O. (2004). Habituation assessment in infancy: From infant control to investigator control. Psychological Methods, 9(1), 70-92. doi:10.1037/1082-989X.9.1.70.\nGilmore, R.O., Baker, T.J., & Grobman, K.H. (2004). Stability in infants’ discrimination of optic flow. Developmental Psychology, 40(2), 259-270. doi:10.1037/0012-1649.40.2.259.\nGilmore, R.O., & Rettke, H.R. (2003). Four-month-olds’ discrimination of optic flow patterns depicting different directions of observer motion. Infancy, 4(2), 177-200. doi:10.1207/S15327078IN0402_02. Materials on Databrary.\nBrown, J., Johnson, M.H., Paterson, S., Gilmore, R.O, Gsödl, M, Longhi, E., & Karmiloff-Smith, A. (2003). Spatial representation and attention in toddlers with Williams syndrome and Down syndrome. Neuropsychologia, 41(8), 1037-1046. doi:10.1016/S0028-3932(02)00299-3\nGilmore, R.O. & Thomas, H. (2002). Examining individual differences in infants’ habituation patterns using objective quantitative techniques. Infant Behavior and Development, 153, 399-412. doi:10.1016/S0163-6383(02)00142-X.\nRosenbaum, D.A., Carlson, R.A., Gilmore, R.O. (2000). Acquisition of intellectual and perceptual-motor skills. Annual Review of Psychology, 52, 453-470. doi:10.1146/annurev.psych.52.1.453.\nJohnson, M.H. & Gilmore, R.O. (1998). Object-centered representations in 8-month-old infants. Developmental Science, 1, 221-225. doi:10.1111/1467-7687.00034.\nGilmore, R.O. & Johnson, M.H. (1997). Body-centered representations for visually-guided action emerge in early infancy. Cognition, 65, B1-B9. dx.doi.org/10.1016/S0010-0277(97)00038-3.\nGilmore, R.O., & Johnson, M.H. (1997). Egocentric action in early infancy: Spatial frames of reference for saccades. Psychological Science, 8(3), 224-230. doi:10.1111/j.1467-9280.1997.tb00416.x\nJohnson, M.H., Gilmore, R.O., Tucker, L.A., & Minister, S.L. (1996). Cortical development and saccadic control: Evidence for vector summation in young infants. Proceedings of TENNET VI, Montreal, Canada. Brain & Cognition, 32(2), 237-243.\nGilmore, R.O., & Johnson, M.H. (1995). Working memory in infancy: Six-month-olds’ performance on two versions of the oculomotor delayed response task. Journal of Experimental Child Psychology, 59, 397-418. doi:10.1006/jecp.1995.1019."
  },
  {
    "objectID": "publications.html#other-non-peer-reviewed-publications",
    "href": "publications.html#other-non-peer-reviewed-publications",
    "title": "publications",
    "section": "Other (non-peer-reviewed) publications",
    "text": "Other (non-peer-reviewed) publications\nGilmore, R.O., Xu, M., & Adolph, K.E. (2021). Data sharing. In Panecker, S. & Stanley, B. (Eds.), Handbook of Research Ethics in Psychological Science, APA Press, Washington, DC. PDF.\nGilmore, R. O. & Adolph, K. E. (2019). Open sharing of research video: Breaking down the boundaries of the research team. In , K. L. Hall, A. L. Vogel, & R. T. Croyle (Eds.), Strategies for team science success: Handbook of evidence-based principles for cross-disciplinary science and practical lessons learned from health researchers. Cham: Springer, pp. 575-583.\nAdolph, K.E., Gilmore, R.O., & Kennedy, J.L. (2017, October). Video data and documentation will improve psychological science. Psychological Science Agenda. https://www.apa.org/science/about/psa/2017/10/video-data.aspx.\nGilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2017, September 7). Practical solutions for the ethical sharing of identifiable research data. Retrieved from https://psyarxiv.com/kew8u.\nSeisler, A.R. & Gilmore, R.O. (2017). Developing R Code for the Processing and Analysis of Optic Flow Data. In Kitzes, J., Turek, D., & Deniz, F. (Eds.). The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences, Oakland, CA: University of California Press, [Online Version]. Retrieved from https://www.practicereproducibleresearch.org.\nGilmore, R. O., & Adolph, K. E. (2017, February 6). Video can make science more open, transparent, robust, and reproducible. Retrieved from https://osf.io/3kvp7.\nGilmore, R.O., & Adolph, K.E. (in press). Open sharing of research video: Breaking the boundaries of the research team, in Advancing Social and Behavioral Health Research through Cross-disciplinary Team Science: Principles for Success. Hall, K., Croyle, R., & Vogel, A. (Eds.). Springer: Philadelphia.\nGilmore, R.O, Gummer, E., & Koedinger, K. (2015). Collaborating on tools, infrastructures, and repositories. In Dede, C. (Ed.) Data-intensive research in education: Current work and next steps, Report on two National Science Foundation sponsored computing research education workshops, 63-73. Computing Research Association.\nGilmore, R.O. & Fesi, J.D. (2009). Infant Perception: Methods of Testing. In B. Goldstein (Ed.), Encyclopedia of Perception, Sage Publishing. doi:10.4135/9781412972000.\nGilmore, R.O., Weinstein, J. & Von Der Heide, R. (2008). The Development and Neuropsychology of Visual Impairment. In A.M. Walker, D.M. Kaufman, G.E. Solomon, and C. Pfeffer (Eds.), Child and Adolescent Neurology for Psychiatrists. Baltimore: Lippincott Williams & Wilkins. 323-347.\nGilmore, R.O. (2003). Where are they going? The perception of information about visual direction in young infants. In B. Hopkins & S.P. Johnson (Eds.), Neurobiology of Infant Vision, Advances in Infancy Research. Westport, CT: Praeger Publishers. 181-210.\nGilmore, R.O. (2003). Toward a neuropsychology of visual development. In S. J. Segalowitz & I. Rapin (Eds.), Handbook of Neuropsychology (2nd Ed.), Vol 8., Part II: Child Neuropsychology. Amsterdam: Elsevier Science. 417-437.\nGilmore, R.O. (2000). The development of representations for perception and action. In J.G. Warhol, N. Fox, & L. Leavitt, (Eds.), The Role of Early Experience in Infant Development: Johnson & Johnson Pediatric Roundtable Series.\nJohnson, M.H., & Gilmore, R.O. (2000). Infancy: Biological processes, in A. Kazdin (Ed.), Encyclopedia of Psychology. Washington, DC: APA Press.\nGilmore, R.O., & Johnson, M.H. (1998). Learning what is where: Oculomotor constraints on the development of spatial cognition. In G. Butterworth & F. Simion, (Eds.), The Development of Sensory, Motor & Cognitive Capacities in Early Infancy: From Sensation to Cognition. Hillsdale, NJ: Erlbaum.\nJohnson, M.H., Gilmore, R.O., & Csibra, G. (1998). Toward a computational model of the development of saccadic control. In J. Richards, (Ed.), The Cognitive Neuroscience of Attention. Hillsdale, NJ: Erlbaum.\nJohnson, M.H., & Gilmore, R.O. (1996). Developmental cognitive neuroscience: A biological perspective on cognitive change. In R. Gelman & T. Au (Eds.), Handbook of Perception and Cognition, 13, Orlando, FL: Academic Press.\nGilmore, R.O., & Johnson, M.H. (1995). Egocentric action in early infancy: Spatial frames of reference for saccades (Developmental Cognitive Neuroscience Tech. Report 95-4). London: U.K. MRC Cognitive Development Unit.\nJohnson, M.H., Gilmore, R.O., Tucker, L.A., & Minister, S.L. (1995). Cortical development and saccadic control: Vector summation in young infants (Developmental Cognitive Neuroscience Tech. Report 95-3). London: U.K. MRC Cognitive Development Unit."
  },
  {
    "objectID": "site-info.html",
    "href": "site-info.html",
    "title": "About the site",
    "section": "",
    "text": "This site is generated in Quarto using RStudio. The rendered site is hosted using GitHub pages.\nHere is additional information about the R session.\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.5.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.24    knitr_1.43        jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "site-info.html#standard-workflow",
    "href": "site-info.html#standard-workflow",
    "title": "About the site",
    "section": "Standard workflow",
    "text": "Standard workflow\n\nOpen project\nPull\nMake changes\nRender site\nPreview site\nCommit changes\nPush to GitHub\n\n\n\n\n\nflowchart LR\n  A[Open project] --&gt; B(Pull)\n  B --&gt; C{Make changes}\n  C --&gt; D[Render site]\n  D --&gt; E[Preview site]"
  },
  {
    "objectID": "participants.html",
    "href": "participants.html",
    "title": "participants",
    "section": "",
    "text": "Research Participant Information\nThe Brain and Behavioral Dynamics Lab is interested in how the visual system develops over time. To reach this goal, we use behavioral, EEG and MRI techniques to study how the infant, child and adult brain responds to motion and pattern.\nIf you are interested in participating in a study or having your child participate, please contact us at psubrainlab@gmail.com."
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html",
    "href": "talk-slides/type-I-type-II-errors.html",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "",
    "text": "To discuss Type I and Type II errors and how they relate to the idea of statistical power."
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html#purpose",
    "href": "talk-slides/type-I-type-II-errors.html#purpose",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "",
    "text": "To discuss Type I and Type II errors and how they relate to the idea of statistical power."
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html#making-decisions",
    "href": "talk-slides/type-I-type-II-errors.html#making-decisions",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "Making decisions",
    "text": "Making decisions\n\nknitr::include_graphics(\"https://mk0abtastybwtpirqi5t.kinstacdn.com/wp-content/uploads/type-1-2-errors.png\")"
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html#setting-decision-thresholds",
    "href": "talk-slides/type-I-type-II-errors.html#setting-decision-thresholds",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "Setting decision thresholds",
    "text": "Setting decision thresholds\n\nGoal: Minimize the probability of making errors\nTypes of errors\n\nFalse positives: Nothing’s going on, but we say otherwise (Type I)\nFalse negatives: Something’s going on, but we miss it (Type II)\n\n\n\nknitr::include_graphics(\"https://i.stack.imgur.com/R0ncP.png\")"
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html#what-do-we-control-what-do-we-measure",
    "href": "talk-slides/type-I-type-II-errors.html#what-do-we-control-what-do-we-measure",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "What do we control? What do we measure?",
    "text": "What do we control? What do we measure?\n\nControl\n\nSample size\nDecision criteria\nHow big a difference (effect size) actually matters\nWidth of “null” or reference distribution\n\nMeasure\n\nOutcomes and their variability"
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html#power-analysis-on-sex-differences-data",
    "href": "talk-slides/type-I-type-II-errors.html#power-analysis-on-sex-differences-data",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "Power analysis on sex differences data",
    "text": "Power analysis on sex differences data\nhttps://gilmore-lab.github.io/sex-differences-in-motion-perception/analysis/preregistration_power_analysis.html"
  },
  {
    "objectID": "talk-slides/type-I-type-II-errors.html#bottom-line",
    "href": "talk-slides/type-I-type-II-errors.html#bottom-line",
    "title": "Type I & Type II Errors and Statistical Power",
    "section": "Bottom line",
    "text": "Bottom line\n\nNeed bigger samples to detect smaller effects with confidence"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html",
    "href": "talk-slides/abramov-etal-2012.html",
    "title": "abramov-etal-2017",
    "section": "",
    "text": "Abramov, I., Gordon, J., Feldman, O., & Chavarga, A. (2012). Sex & vision I: Spatio-temporal resolution. Biology of Sex Differences, 3(1), 20. bsd.biomedcentral.com. Retrieved from http://dx.doi.org/10.1186/2042-6410-3-20"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#discussion-of-abramov2012-da",
    "href": "talk-slides/abramov-etal-2012.html#discussion-of-abramov2012-da",
    "title": "abramov-etal-2017",
    "section": "",
    "text": "Abramov, I., Gordon, J., Feldman, O., & Chavarga, A. (2012). Sex & vision I: Spatio-temporal resolution. Biology of Sex Differences, 3(1), 20. bsd.biomedcentral.com. Retrieved from http://dx.doi.org/10.1186/2042-6410-3-20"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#who-were-the-participants",
    "href": "talk-slides/abramov-etal-2012.html#who-were-the-participants",
    "title": "abramov-etal-2017",
    "section": "Who were the participants?",
    "text": "Who were the participants?\n\nAdults (faculty, graduate and undergraduate students at Brooklyn College, some high school students)\n\\(n=36\\) females (16-38 years; mean = 23.5 years); \\(n=16\\) males (16-37 years; mean 24.3 years)\n\n\n“These numbers of participants are appreciably larger than those in the vast majority of detailed psychophysical studies of vision.”"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#what-tasks-did-they-perform",
    "href": "talk-slides/abramov-etal-2012.html#what-tasks-did-they-perform",
    "title": "abramov-etal-2017",
    "section": "What tasks did they perform?",
    "text": "What tasks did they perform?\n\nExample display\n\n\nPrimary\n\nSpatio-Temporal Contrast Sensitivity Function (ST-CSF)\n\n\nContrast sensitivity function example\n\n\n\n\n\nhttps://understandinglowvision.com/2-0-contrast-sensitivity-function/\n\n\n\n\n\n\n\nSecondary\n\nStereopsis or binocular depth perception (Titmus Fly Book Test; Randot Stereo Acuity Test; TNO anaglypic random-dot plates)\nColor perception\nAcuity"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#what-specific-variablesmeasures-were-of-interest",
    "href": "talk-slides/abramov-etal-2012.html#what-specific-variablesmeasures-were-of-interest",
    "title": "abramov-etal-2017",
    "section": "What specific variables/measures were of interest?",
    "text": "What specific variables/measures were of interest?\n\nI manipulate independent variables (controlled variables or ‘inputs’); ‘Dey’ provide information about dependent variables (responses/outcome variables or ‘outputs’)\n\n\nST-CSF thresholds\n\nat different spatial frequencies and temporal frequencies"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#how-many-visitsdata-collection-sessions",
    "href": "talk-slides/abramov-etal-2012.html#how-many-visitsdata-collection-sessions",
    "title": "abramov-etal-2017",
    "section": "How many visits/data collection sessions?",
    "text": "How many visits/data collection sessions?\n\n15+ laboratory sessions\n\n\n“Furthermore, each of our participants had to complete our entire Battery of tests of vision; this entailed coming to the laboratory for fifteen or more sessions of approximately one hour.”"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#how-were-the-data-analyzed",
    "href": "talk-slides/abramov-etal-2012.html#how-were-the-data-analyzed",
    "title": "abramov-etal-2017",
    "section": "How were the data analyzed?",
    "text": "How were the data analyzed?"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#group-contrast-sensitivity-functions-females",
    "href": "talk-slides/abramov-etal-2012.html#group-contrast-sensitivity-functions-females",
    "title": "abramov-etal-2017",
    "section": "Group contrast sensitivity functions (females)",
    "text": "Group contrast sensitivity functions (females)\n\n\n\n\n\nAbramov et al. 2012, Figure 1"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#group-contrast-sensitivity-functions-males",
    "href": "talk-slides/abramov-etal-2012.html#group-contrast-sensitivity-functions-males",
    "title": "abramov-etal-2017",
    "section": "Group contrast sensitivity functions (males)",
    "text": "Group contrast sensitivity functions (males)\n\n\n\n\n\nAbramov et al. 2012, Figure 1"
  },
  {
    "objectID": "talk-slides/abramov-etal-2012.html#ratios-of-group-contrast-sensitivity-functions-malesfemales",
    "href": "talk-slides/abramov-etal-2012.html#ratios-of-group-contrast-sensitivity-functions-malesfemales",
    "title": "abramov-etal-2017",
    "section": "Ratios of group contrast sensitivity functions (Males/Females)",
    "text": "Ratios of group contrast sensitivity functions (Males/Females)\n\n\n\n\n\nAbramov et al. 2012, Figure 1"
  }
]